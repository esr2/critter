\documentclass[12pt]{report}
\usepackage{setspace}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

%todonotes
\usepackage{todonotes}
\newcommand{\todoin}{\todo[inline]}

%code listings%%%
\usepackage{listings}
%\lstset{language=C}
\lstset{
	basicstyle=\ttfamily,
	tabsize=2,
	frame=single,
	breaklines=true,
	breakatwhitespace=true,
	breakindent=25pt,
	defaultdialect=[ANSI]C,
	showstringspaces=false
 }
%\def\lstlistlistingname{Code Excerpts}
\def\lstlistingname{Figure}
\newcommand{\refCode}{\lstlistingname \hspace{1mm}}
\usepackage[scaled=.8]{luximono}
   \usepackage[T1]{fontenc}
   \usepackage{textcomp}
%%%

%project name
\usepackage{xspace}
\newcommand{\projectname}{Project Name\xspace} 
\newcommand{\programName}{CritTer\xspace}

\usepackage{booktabs} %pretty tables
\usepackage[pdfauthor={ErinRosenbaum},pagebackref=true,pdftex]{hyperref}
%pdftitle={\projectname}

\newcounter{checkCounter}
\usepackage{ifthen}
\newcommand\chk[2][default]{\noindent%
  \refstepcounter{checkCounter} \thecheckCounter \hspace{1mm}
  \ifthenelse{\equal{#1}{default}}{
    #2 \label{#2} }{
    #2 \label{#1}
  }
}
\newcommand\chkref[1]{\hspace{.1mm} \ref{#1} \hspace{2mm}#1}

\usepackage{color}

\usepackage{versions}
\includeversion{PRINT}
\excludeversion{COLOR}

%for title page
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

%\doublespacing			% Ask per individual, also remove extra space in section headings

\begin{document}
\input{titlePage}
\pagenumbering{roman}

\listoftodos

\begin{abstract}
\todoin{Add an abstract}
\end{abstract}

\tableofcontents
\listoftables
\listoffigures

\cleardoublepage
\pagenumbering{arabic}

\chapter{Problem Description}

\begin{table}%[h]
	\caption{Error Checking}
	\label{errorChecking}
	\begin{center}
	\begin{tabular}{ccc}
		\toprule
		Types of Errors & Tools for Literature & Tools for Code \\
		\midrule
		Syntactic & Spell Check & Compiler \\
		Semantic & Grammar Check & \\ 
		Substantive & Audience/Grader & User/Tests \\
		\bottomrule
	\end{tabular}
	\end{center}
\end{table}

When one writes, one encounters three different types of errors: syntactic, semantic and substantive.  
In the case of writing literature, these errors take the form of spelling, grammar and substantive
mistakes. When writing code, they form syntax errors, poorly written code and malfunctioning code. 
Both spelling mistakes and syntax errors represent text that contains something outside the language 
(be it English, C, etc.). A passage with bad grammar and poorly written code both denote text that is 
technically valid but hard to understand. Finally, illogical arguments and malfunctioning code both 
imply errors in the ideas behind the text. 
There are tools to help one find these errors in both literature and code (see Table \ref
{errorChecking}). Spelling and grammar check exist in nearly every word processor; the reader 
highlights substantive errors in literature. With code, the compiler shows semantic errors and the user/
testing reveal substantive errors. Yet semantic error checking for code has been addressed by 
relatively few tools.

From a different point of view, this problem can be formulated in terms of software quality. 
Namely, there are two perspectives on software quality: that of the user and that of the programmer. 
Users evaluate software on whether or not it behaves as it ought to. In contrast, programmers evaluate 
software on whether or not it is easily maintainable. Minimally, maintainability implies that 
code is easy to read and update. Evaluating the user's perspective of a program is common and most 
easily accomplished through automated testing. Though it is possible to evaluate the programmers' 
perspective, tools that do so only check for certain qualities. Unfortunately, code quality is 
subjective, any tool that only performs pre-defined inspections will never be satisfactory to every 
programmer.

The biggest reason to perform semantic error checking is to improve readability (the 
ease with which another programmer can understand a piece of code). In the same way that 
grammatical errors in a paper often confound its underlying arguments, poorly written code can easily 
obscure its underlying function. Furthermore, readable code is easy to revise and update later. 

In the academic world, professors and TA's often read students' code, especially in introductory level
courses. In these courses, much of the focus is often on enforcing ``good style'' (though the definition 
varies from professor to professor).  The successful implementation of automated semantic error 
checking can immediately save work for professors by replacing the process of writing the same set of 
stylistic comments to many students with a set of automated warnings. Students can also directly 
benefit by applying this tool to their code before submitting assignments --- giving them the chance to 
improve their grades as well as their coding habits.

In an industrial setting, where it is necessary to read or edit another's code, maintaining readability is 
essential. Projects are often handed over to new employees or teams who are then expected to be 
able to contribute immediately. Poorly organized or written code makes this daunting task 
onerous. Most successful software companies make use of a codified internal style but the 
enforcement of this policy falls to the employees. Many transgressions are simply due to inattention 
and could easily be solved by an automated reminder system. Such a tool would reduce the need to 
bother one's peers with another round of reviews, allowing the entire team to be more productive. 

\chapter{Related Products}

There are some tools that try to fill the semantic error checking gap. Each approaches the 
problem differently, but all succeed in finding some semantic errors. Three such tools are Splint \cite
{splint-manual} , PMD \cite{pmd}, and Checkstyle \cite{checkstyle}.

 \todoin{add explicit comparison between these tools and my tool}
\section{Splint}
Splint is a tool for ``statically checking C programs for security vulnerabilities and programming 
mistakes" \cite[p.\ 9]{splint-manual}. It works exactly as my program does from the students'
perspective, i.e.\ as a command-line program which prints warnings and errors to \lstinline{stdout}. 
Splint displays warnings about basic semantic errors like assignments with mismatched types and 
ignored return values. With more effort, programmers can add annotations (i.e.\ fancy comments) that 
give Splint a specification to check against. These annotations allow for stronger checks like memory 
management, null pointers and ``violations of information hiding'' \cite[p. 9]{splint-manual}. An 
example of annotations in action are the following abstract type declarations (\refCode \ref{splint-annotations}).

\begin{figure}[h]
\caption{Splint Annotations} 
\label{splint-annotations}
\begin{lstlisting}[frame=single, language=C]
typedef /*@abstract@*/ /*@mutable@*/ char *mstring;
typedef /*@abstract@*/ /*@immutable@*/ int weekDay;
\end{lstlisting}
\small{These annotations define \lstinline{mstring} and \lstinline{weekDay} as abstract types and further specify that they are mutable/immutable respectively.}
\end{figure}

While these annotations provide an extensive feature set, they are a huge inconvenience. They 
require programmers to specifically write their code to meet the specification, not only of the client, but 
also of the tool. For new programmers (often the ones who need the most error checking), these 
annotations are almost impossible to implement on top of learning to program as suggested by  
David Evans (one of the authors) in a private email. He states:
\begin{quote} \singlespacing
One of the goals of the original design of 
Splint was for programmers who add no annotations to start getting some useful warnings right away, 
including warnings that encourage them to start adding annotations.  For some aspects, such as 
\lstinline{/*@null@*/} annotations I think this has worked okay, but for others like abstract types, 
memory management, etc. I don't think it has worked very well, and the warnings on these issues tend 
to either make developers want to stop using Splint, or at least just turn off all the warnings of that type, 
rather than start adding the annotations needed to enable better checking. \cite{evans-email} 
\end{quote}

\section{PMD and Checkstyle}
PMD is a tool for checking Java Code that is integrated into a dozen or so different popular IDEs.
PMD comes premade with over 250 checks broken up mostly by purpose such as Braces Rules, 
Basic Rules, Coupling Rules, etc. Some checks also deal explicitly with a certain 
library or platform like Android, Jakarta and JUnit. PMD functions by passing source code into a 
JavaCC-generated parser and receiving an Abstract Syntax Tree (a.k.a.\ AST, a tree-based model of 
the source code). PMD then traverses the AST and calls each rule in the RuleSet to check for any
violations. This pattern of examining a tree of nodes is called the Visitor Pattern \cite{design-patterns}. 
The RuleSet is an XML file that can be edited to augment the functionality of PMD with customized 
rules. Rules are written in their own classes and extend a base implementation. The rule itself can 
override three functions (start, visit and end) to perform various checks against the source code based 
on the nodes in the AST. Here is the ``dummy" example from the PMD website which counts how 
many expressions are in the source code (see \refCode \ref{pmd-rule}).
\todoin{why PMD doesn't work}

\begin{figure}
\caption[Example PMD Rule]{Example PMD Rule counting the number expressions}
\label{pmd-rule}
\begin{lstlisting}[language=Java]
package net.sourceforge.pmd.rules;

import java.util.concurrent.atomic.AtomicLong;
import net.sourceforge.pmd.AbstractJavaRule;
import net.sourceforge.pmd.RuleContext;
import net.sourceforge.pmd.ast.ASTExpression;

public class CountRule extends AbstractJavaRule {

	private static final String COUNT = "count";

	@Override
	public void start(RuleContext ctx) {
		ctx.setAttribute(COUNT, new AtomicLong());
		super.start(ctx);
	}

	@Override
	public Object visit(ASTExpression node, Object data) {
		// How many Expression nodes are there in all files parsed! 
		RuleContext ctx = (RuleContext)data;
		AtomicLong total = (AtomicLong)ctx.getAttribute(COUNT);
		total.incrementAndGet();
		return super.visit(node, data);
	}

	@Override
	public void end(RuleContext ctx) {
		AtomicLong total = (AtomicLong)ctx.getAttribute(COUNT);
		addViolation(ctx, null, new Object[] { total });
		ctx.removeAttribute(COUNT);
		super.start(ctx);
	}
}
\end{lstlisting}
\end{figure}

Checkstyle mimics PMD in function but provides different checks out of the box (namely those 
regarding duplicate code, class design, whitespace, etc). It also uses the Visitor Pattern and 
provides ways to examine the beginning and ends of the tree as well as each node. New rules are 
added through an XML file and similarly passed to Checkstyle at runtime. Here is example check 
which determines how many methods are in a class (see \refCode \ref{checkstyle-rule}).
\todoin{pad this out into its own}
\nocite{framaC}

\begin{figure}
\caption[Example Checkstyle Check]{Example Checkstyle Check counting the number of methods in 
a class}
\label{checkstyle-rule}
\begin{lstlisting}[language=Java]
package com.mycompany.checks;
import com.puppycrawl.tools.checkstyle.api.*;

public class MethodLimitCheck extends Check
{
    private static final int DEFAULT_MAX = 30;
    private int max = DEFAULT_MAX;

    @Override
    public int[] getDefaultTokens()
    {
        return new int[]{TokenTypes.CLASS_DEF, TokenTypes.INTERFACE_DEF};
    }

    @Override
    public void visitToken(DetailAST ast)
    {
        // find the OBJBLOCK node below the CLASS_DEF/INTERFACE_DEF
        DetailAST objBlock = ast.findFirstToken(TokenTypes.OBJBLOCK);
        
        // count the number of direct children of the OBJBLOCK that 
        // are METHOD_DEFS
        int methodDefs = objBlock.getChildCount(TokenTypes.METHOD_DEF);
        
        // report error if limit is reached
        if (methodDefs > this.max) {
            log(ast.getLineNo(),
                "too many methods, only " + this.max + " are allowed");
        }
   }
}
\end{lstlisting}
\end{figure}


\chapter{Version 1}

\begin{singlespace}
\textit{Note: the following chapters describe my progress in creating \projectname by looking at each 
successive version. If you would like to skip ahead please go to Chapter \ref{chap:FinalVersion} on 
page \pageref{chap:FinalVersion}.} \end{singlespace}
\vspace{3mm} 

This version represents the basic implementation of my goal: a customizable style checker for C code.
It is built off of Flex and Bison which create a lexical analyzer and a parser from a set of source 
files. These two elements combine into one larger program, \programName, which takes a .c file as 
input.  \programName parses the input file by recognizing each code construction as part of the valid 
C grammar (these possible constructions are known as a grammar rules). While parsing the code, 
\programName executes any function associated with the grammar rule (see \refCode \ref{grammar1.0}, 
where functions are underlined). These functions are the checks which are stored in a different file. 
Additionally, checks can be called from the beginning or end of each file or the entire program.
\todoin{assume readers know about context free grammars -- explicitly use that term and add a footnote to explain it}
\todoin{explain locations somewhere (maybe final version?)}
\todoin{mention begin/end of file/program calls}

\begin{figure} 
\caption{Excerpt of the Grammar File from v1.0}
\label{grammar1.0}
\begin{lstlisting}[language=Caml, escapechar=\%]
parameter_list
	: parameter_declaration
	| parameter_list `,' parameter_declaration %\underline{\{tooManyParameters(@1);\}}%
	;

parameter_declaration
	: declaration_specifiers declarator
	| declaration_specifiers abstract_declarator
	| declaration_specifiers
	;

selection_statement
	: IF `(' expression `)' statement 	%\underline{\{\$\$ = IF\_SELECTION; ifHasBraces(\$5, @\$);\}}%
	| IF `(' expression `)' statement ELSE statement %\underline{\{\$\$ = IF\_ELSE\_SELECTION, ifHasBraces(\$5, @\$); ifHasBraces(\$7, @\$);\}}%
	| SWITCH `(' expression `)' statement
	;

iteration_statement
	: WHILE `(' expression `)' statement
	| DO statement WHILE `(' expression `)' `;'
	| FOR `(' expression_statement expression_statement `)' statement
	| FOR `(' expression_statement expression_statement expression `)' statement
	;

function_definition
	: declaration_specifiers declarator declaration_list compound_statement %\underline{\{isFunctionTooLong(@\$);\}}%
	| declaration_specifiers declarator compound_statement %\underline{\{isFunctionTooLong(@\$);\}}%
	| declarator declaration_list compound_statement %\underline{\{isFunctionTooLong(@\$);\}}%
	| declarator compound_statement %\underline{\{isFunctionTooLong(@\$);\}}%
	;
\end{lstlisting}
\end{figure} 
\newpage

\section{Checks}

To check a stylistic issue, one must first figure out how the issue is represented in the grammar and 
then add a function call inside that grammar rule. Each check can not only take advantage of the type 
of construction being formed (like Function \ref{hasBraces} in Table \ref{implementedChecks1.0}), it 
can also look at the location of each construction. This allows checks to determine the length of a 
construction (like Function \ref{isFunctionTooLong}). It also allows checks to determine if they are still 
working with the same construction (like Function \ref{tooManyParameters}). Function \ref{CPlusPlusComments} 
is actually implemented through the lexer and is called on recognition of ``\lstinline{\\}''. \refCode \ref{checks.c1.0} 
shows examples of check functions.

\begin{table}
	\caption{Implemented Checks in v1.0}
	\label{implementedChecks1.0}
	\begin{center}
	\begin{tabular}{l p{10cm}}
		\toprule
		Function & Purpose \\
		\midrule
		\chk[hasBraces]{ifHasBraces} & Determines if the statement following an \lstinline!if! is surrounded by \{\} \\
		\chk{isFunctionTooLong} & Determines if a function's length exceeds the maximum number of lines\\
		\chk{tooManyParameters} & Determines if there a function exceeds the maximum number of input parameters \\
		\chk{CPlusPlusComments} & Throws an error on finding C++ style single-line comments \\
		\bottomrule
	\end{tabular}
	\end{center}
\end{table}

\begin{figure}
\caption{Excerpt of Checks.c from v1.0}
\label{checks.c1.0}
\begin{lstlisting}[language=C]
void ifHasBraces(enum tree_code statementValue, YYLTYPE location) {
	if (statementValue != COMPOUND_STATEMENT) {
		lyyerror(location, "Please use braces after all if statements");
	}
}

void isFunctionTooLong(YYLTYPE location) {
	int MAX_FUNCTION_LENGTH = 100; /* Arbitrary Maximum */
	
	if (location.last_line - location.first_line + 1 >= MAX_FUNCTION_LENGTH) {
		lyyerror(location, "Function is too lengthy");
	}
}

void tooManyParameters(YYLTYPE location) {
	int MAX_NUM_PARAMETERS = 7; /* Arbitrary Maximum */
	static int numParameters = -1;
	static YYLTYPE prevLoc;
	
	if (location.first_line != prevLoc.first_line || numParameters == -1) {
		if (numParameters != -1 && numParameters >= MAX_NUM_PARAMETERS) {
			char string[200];
			sprintf(string,
					"Please use less than %d function parameters, you used %d",
					MAX_NUM_PARAMETERS, numParameters);
			lyyerror(prevLoc, string);
		}
		numParameters = 1;
	}
	numParameters++;
	prevLoc = location;
}

void CPlusPlusComments(YYLTYPE location) {
	lyyerror(location, "Don't use C++ style comments");
}

\end{lstlisting}
\end{figure}


\section{Limitations}
There are two main limitations to this version:\ adding a check is a hassle and C preprocessor 
directives are not handled. As described above, adding a check is nontrivial because of the 
interaction with the grammar file. It requires users to be reasonably familiar with not only grammar files 
but the C grammar itself. The second limitation is that all macros except \lstinline{#include} are 
completely ignored. While unfortunate, this implementation is far easier than the alternative:\ 
effectively compiling and tracking all definitions, expressions and \lstinline{#ifndef}s. Includes are 
parsed only so far as to include any local file -- all standard files are ignored because they rely on 
types that were defined as macros. To make this system work for average student C files, the lexer has 
\todo{``average student C files'' -- reword?}
the \lstinline{size_t} type built in. A minor issue is \programName does not follow the paths of files -- 
meaning that it will not run on code residing in a subfolder of the working directory.

\section{Version 1.1}
This version simply adds more functionality (checks) to version 1.0 without changing the overall structure of \programName.

\subsection{Checks}
Version 1.1 changes Function \ref{hasBraces} from Version 1.0 as well as adds several new checks (see 
Table \ref{implementedChecks1.1}). This version also stores comment text and locations for the 
duration of the program. The appropriate comment is found by searching through the stored location-
comment pairs for locations within a certain range of a specified location. For example, in Function 
\ref{checkForComment}, each function definition results in a search for any comment within 5 lines of the 
declaration. Comments and their locations are stored in two dynamically sized global arrays.

\begin{table}
\caption{Additional Checks in 1.1}
\label{implementedChecks1.1}
	\begin{tabular}{l p{10cm}}
		\toprule
		Function & Purpose \\
		\midrule
		\chkref{hasBraces} & Determines if the statement following an \lstinline!if!, \lstinline$for$, or \lstinline$while$ is surrounded by \lstinline!{}! \\
		\chk{checkForComment} & Throws an error if a function does not have an associated comment \\
		\chk{switchHasDefault} & Throws an error if a switch statement does not include a \lstinline$default$ case \\
	\end{tabular}
\end{table}

\chapter{Version 2}
made sax style implementation of version 1.1

\section{Limitations}
because of the ambiguous nature of the grammar its impossible to get some of the begin calls at the 
actual beginning of the construct.

\section{Version 2.1}

\begin{table}[h]
\caption{Additional Checks in 2.1}
\label{implementedChecks2.1}
	\begin{tabular}{l p{10cm}}
		\toprule
		Function & Purpose \\
		\midrule
		\chk{switchCasesHaveBreaks} & Make sure all cases (including the \lstinline$default$) have a \lstinline$break$ statement \\
		\chk{tooDeeplyNested} & Throws error if a region is too deeply nested \\
		\chk{useEnumNotConstOrDefine} & Throws error for using \lstinline$const$ or \lstinline$#define$ to define integral constants \\
		\bottomrule
	\end{tabular}
\end{table}

\chapter{Final Product aka Version X}
\label{chap:FinalVersion}

\chapter{What \programName Does}

\programName reads in a set of C source code files and determines if they contain any of the 
semantic errors that the administrator has defined. It is run through the command line inside one's 
working directory. \programName is given a list of .c/h files to check and reads through each in the 
given order, stopping to read through any locally included header files. Upon encountering an error,
\programName prints out the full location of the error, a warning level and an error message to 
\lstinline{stderr} (an example is shown in \refCode \ref{errorExample}). 

\begin{figure}
\caption{Example Error and Corresponding Message}
\label{errorExample}
\begin{minipage}[b]{0.5\textwidth}
\hspace{1mm} test.c:
\begin{lstlisting}[numbers=left, firstnumber=92,xleftmargin=1cm]
	for (int q = 0; q<5; q++) {
		printf("hi");
	}
\end{lstlisting}
\end{minipage}
\hspace{-10mm}
\begin{minipage}[b]{0.5\textwidth}
\hspace{8mm} stderr:
\begin{lstlisting}[xleftmargin=1cm]
test.c:92.22-92.23: big problem: Do not use magic numbers
\end{lstlisting}
\end{minipage} \\
\small{Here, \programName is complaining that the for loop's exit condition contains a `magic number', in this case 5. The error message contains the location of the error, the warning level and then the error message.}
\end{figure}

The administrator is responsible for defining the set of checked semantic errors. \programName 
comes with a set of predefined checks that the administrator may use or discard at their discretion. 
Checks are event driven and are called when the appropriate element in the code is reached. For 
example, checking for a minimum length of each variable name happens when \programName 
recognizes a variable inside a declaration. The administrator can write their own checks as functions 
which they setup to be involked at each of the relevant callback points.

\chapter{How \programName Works}

\programName is built on top of Bison and Flex, a parser generator and a lexical analyzer 
respectively. These two programs each take in a specification file which define a set of tokens and a 
corresponding context free grammar. They work in tandem to read code, parse it into the appropriate 
tokens and then determine each grammar construct. \programName's specification files 
describe valid ANSI C code but \programName does not compile or in anyway track the contents. This 
means, for example, that \programName sees any variable or function name as just as an 
\lstinline{IDENTIFIER} (which is defined as any set of letters that does not already designate a 
variable type). Bison and Flex also track the location of any token or grammar construct in a 
\lstinline{YYLTYPE} structure. (Normally a \lstinline{YYLTYPE} contains 4 fields, \lstinline{first_line}, 
\lstinline{first_column}, \lstinline{last_line} and \lstinline{last_column} however I have also added a 
\lstinline{filename} field in order to produce more accurate checks and error messages across a set of 
files.) Each grammar rule can contain multiple actions which consist of C code. These actions can 
also reference the location of any of single component of or the entire rule. \programName calls the 
event handlers from these actions, passing in the location of the relevant construction (see \refCode 
\ref{grammar}, where actions are underlined). Some actions are hidden in subroutines in order to 
avoid ambiguities within the grammar.

\begin{figure} 
\caption{Excerpt of the Grammar}
\label{grammar}
\begin{lstlisting}[language=Caml, escapechar=\%]
parameter_list
	: parameter_declaration											%\underline{\{h\_registerParameter(@\$);\}}%
	| parameter_list ',' parameter_declaration	%\underline{\{h\_registerParameter(@3);\}}%
	;

parameter_declaration
	: declaration_specifiers declarator
	| declaration_specifiers abstract_declarator
	| declaration_specifiers
	;

beginIF : /*empty*/ %\underline{\{beginIf(@\$);\}}%

selection_statement
	: IF beginIF '(' expression ')' statement %\underline{\{endIf(@\$);\}}%
	| IF beginIF '(' expression ')' statement ELSE %\underline{\{endIf(@6); beginElse(@7);\}}% statement	%\underline{\{endElse(@9);\}}%
	| SWITCH %\underline{\{beginSwitch(@1);\}}% '(' expression ')' statement %\underline{\{endSwitch(@\$);\}}%
	;

beginFOR : /*empty*/ %\underline{\{beginFor(@\$);\}}%

iteration_statement
	: WHILE %\underline{\{beginWhile(@1);\}}% '(' expression ')' statement %\underline{\{endWhile(@\$);\}}%
	| DO %\underline{\{beginDoWhile(@1);\}}% statement WHILE '(' expression ')' ';' %\underline{\{endDoWhile(@\$);\}}%
	| FOR beginFOR '(' expression_statement expression_statement ')' statement	%\underline{\{endFor(@\$);\}}%
	| FOR beginFOR '(' expression_statement expression_statement expression ')' statement %\underline{\{endFor(@\$);\}}%
	| FOR beginFOR '(' declaration expression_statement ')' statement %\underline{\{endFor(@\$);\}}%
	| FOR beginFOR '(' declaration expression_statement expression ')' statement	%\underline{\{endFor(@\$);\}}%

\end{lstlisting}
\end{figure} 

\programName is event based and is largely inspired by SAX \cite{saxHomepage}. SAX allows one to 
create event handlers for the beginning and end of each XML element as well as capture the text in 
between. \programName calls event handlers at the beginning and end of constructs (functions, 
declarations, statements, parameter lists, etc) as well as when it finds singular elements (variable 
names, \lstinline{break} statements, parameters, etc). In the code, handlers are prefaced by the words 
\lstinline{begin}, \lstinline{end} and \lstinline{register} to signal at what point each is called (as shown 
in \refCode \ref{grammar}). Each handler is passed, at minimum, the location of the relevant code; 
however, \lstinline{begin} handlers only know the location of the beginning of the construct since the 
entire construct has not been read yet. Each of these event handlers exist in the file sax.c/h which in 
turn call the administrator defined checks. While these checks could be written into the event handlers 
themselves, it is conventional to separate them into their own functions (and files) in order to preserve 
the readability of the sax.c file and the code in general.

\nocite{*}
\bibliographystyle{plain}
\bibliography{Bibliography}

\end{document}  