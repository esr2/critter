\documentclass[12pt]{report}
%\documentclass[12pt, twoside]{report}
%\documentclass[12pt, draft]{report}
\usepackage{setspace}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\usepackage{fancyhdr}
\setlength{\headheight}{15pt}
\pagestyle{fancy}
\fancyhead{}
\renewcommand{\chaptermark}[1]{\markboth{\thechapter.\ #1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection.\ #1}}
\renewcommand{\headrulewidth}{0pt}
\fancyhead[RE]{\rightmark}
\fancyhead[LO]{\leftmark}

\pagestyle{plain}

\usepackage[Lenny]{fncychap}

%todonotes
\usepackage{todonotes}
\newcommand{\todoin}{\todo[inline]}

%code listings%%%
\usepackage{listings}
%\lstset{language=C}
\lstset{
	basicstyle=\ttfamily,
	tabsize=2,
	frame=single,
	breaklines=true,
	breakatwhitespace=true,
	breakindent=25pt,
	defaultdialect=[ANSI]C,
	showstringspaces=false
 }
%\def\lstlistlistingname{Code Excerpts}
\def\lstlistingname{Figure}
\usepackage[scaled=.8]{luximono}
   \usepackage[T1]{fontenc}
   \usepackage{textcomp}
%%%

%project name
\usepackage{xspace}
\newcommand{\programName}{CritTer\xspace}

\usepackage{booktabs} %pretty tables
\usepackage[pdfauthor={ErinRosenbaum},pagebackref=true,pdftex]{hyperref}
\def\chapterautorefname{Chapter}
\def\sectionautorefname{Section}
%pdftitle={\projectname}

\usepackage{color}

\usepackage{versions}
\includeversion{PRINT}
\excludeversion{COLOR}

\usepackage[font={sf, small}, labelfont=bf]{caption, subcaption}
\ExecuteOptions{tight,TABTOPCAP}

\usepackage{longtable}
\usepackage{multirow}

\usepackage{appendix}

\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\renewcommand{\floatpagefraction}{0.75}

%for title page
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\doublespacing			% Ask per individual, also remove extra space in section headings

\begin{document}
\singlespacing
\input{titlePage}
\pagenumbering{roman}

\listoftodos

\begin{abstract}
Semantic errors cause poorly written and\slash or hard to read code. Sadly, relatively few tools have 
addressed automated semantic error checking and even fewer are customizable or written for C. 
\programName (Critique from the Terminal) fills this gap by providing a tool to check for administrator 
defined semantic errors in C code. It uses a SAX style of event based programming to produce errors as 
the code is being read. Administrators can use the predefined checks or create their own to enforce 
coding standards or help grade and teach ``good style'' to students.
\end{abstract}

\renewcommand{\abstractname}{Acknowledgements}
\begin{abstract}

This thesis has been simultaneously one of the hardest and most rewarding experiences of my 
academic career. Transforming a simple idea into a functional, and more importantly useful, program 
was extremely satisfying and is a boost to my confidence as I enter the professional world. I am 
thoroughly indebted to many individuals who supported me through this process. Unequivocally, I owe 
my greatest and most profound thanks to my advisor, Dr.~Robert Dondero. Dr.~Dondero patiently met 
with me every week this year and helped me in everything from research and general software 
development to programming design tactics and writing skills. Without his appreciation of good style, this 
thesis would never have made it to its current state.

I would also like to express my gratitude to Professor Brian Kernighan for helping me enter the Computer 
Science department my sophomore year and putting up with my two Junior Projects. Without his help 
and support, I would not have become a successful CS major nor had a beneficial internship last 
summer. 

There are various individuals who have supported me through this entire process. Ashton Brown and 
Slater Stich have been two of my closest friends and biggest supporters this year and through my entire 
college career. Without their help, I would not have been as productive or successful in my efforts on this 
thesis; without their friendship, my college career would have been significantly less enjoyable. I would 
also like to thank my teammates for being a wonderful, if often slightly annoying, set of brothers -- I will 
actively miss all of the `family' dinners next year. Additionally, I'd like to thank Marty Crotty, my coach, 
who has made me a tougher person and a better competitor. Finally I'd like to thank my parents and my 
sisters who constantly provide me with support and laughter. I owe all my success to them.

\end{abstract}

\tableofcontents
\listoftables
\listoffigures

\cleardoublepage
\pagenumbering{arabic}
\pagestyle{fancy}
\doublespacing

\chapter{Introduction}

\begin{table}%[h]
	\begin{center}
	\begin{tabular}{ccc}
		\toprule
		Types of Errors & Tools for Literature & Tools for Code \\
		\midrule
		Syntactic & Spell Check & Compiler \\
		Semantic & Grammar Check & \\ 
		Substantive & Audience\slash Grader & User\slash Tests \\
		\bottomrule
	\end{tabular}
	\end{center}
	\caption{Error Checking}
	\label{errorChecking}
\end{table}

When one writes, one encounters three different types of errors: syntactic, semantic and substantive.  
In the case of writing literature, these errors take the form of spelling, grammar and substantive
mistakes. When writing code, they form syntax errors, poorly written code and malfunctioning code. 
Both spelling mistakes and syntax errors represent text that contains something outside the language 
(be it English, C, etc.). A passage with bad grammar and poorly written code both denote text that is 
technically valid but hard to understand. Finally, illogical arguments and malfunctioning code both 
imply errors in the ideas behind the text. 
There are tools to help one find these errors in both literature and code (see \autoref{errorChecking}). 
Spelling and grammar check exist in nearly every word processor; the reader highlights substantive 
errors in literature. With code, the compiler shows semantic errors and the user\slash 
testing reveals substantive errors. Yet semantic error checking for code has been addressed by 
relatively few tools.

From a different point of view, this problem can be formulated in terms of software quality. 
Namely, there are two perspectives on software quality: that of the user and that of the programmer. 
Users evaluate software on whether or not it behaves as it ought to. In contrast, programmers evaluate 
software on whether or not it is easily maintainable. Minimally, maintainability implies that 
code is easy to read and update. Evaluating the user's perspective of a program is common practice and 
most easily accomplished through automated testing. Though it is possible to evaluate the programmer's 
perspective, tools that do so only check for certain qualities. Unfortunately, code quality is 
subjective, any tool that only performs pre-defined inspections will never be satisfactory to every 
programmer.

The biggest reason to perform semantic error checking is to improve readability (the 
ease with which another programmer can understand a piece of code). In the same way that 
grammatical errors in a paper often confound its underlying arguments, poorly written code can easily 
obscure its underlying function. Furthermore, readable code is easy to revise and update later. 

In the academic world, professors and TA's often read students' code, especially in introductory level
courses. In these courses, much of the focus is often on enforcing ``good style'' (though the definition 
varies from professor to professor).  The successful implementation of automated semantic error 
checking can immediately save work for professors by replacing the process of writing the same set of 
stylistic comments to many students with a set of automated warnings. Students can also directly 
benefit by applying this tool to their code before submitting assignments --- giving them the chance to 
improve their grades as well as their coding habits.

In an industrial setting, where it is necessary to read or edit another's code, maintaining readability is 
essential. Projects are often handed over to new employees or teams who are then expected to be 
able to contribute immediately. Poorly organized or written code makes this daunting task 
onerous. Most successful software companies make use of a codified internal style but the 
enforcement of this policy falls to the employees. Many transgressions are simply due to inattention 
and could easily be solved by an automated reminder system. Such a tool would reduce the need to 
bother one's peers with another round of code reviews, allowing the entire team to be more productive. 

\chapter{Related Products}

Many tools exist to help improve code. Minimally, compilers often produce warnings about unused code 
or poorly placed comparisons\slash assignments. Tools like Clang\cite{clang} and Uno\cite{Uno} go 
even further and look for bugs such as uninitialized variables, out of bounds array indexing and memory 
errors. Some tools try to fill the semantic error checking gap. Each approaches the problem differently, 
but all succeed in finding some semantic errors. Three such tools are 
\hyperref[sec:splint]{Splint}\cite{splint-manual} , \hyperref[sec:pmdAndCheckstyle]{PMD}\cite{pmd}, and 
\hyperref[sec:pmdAndCheckstyle]{Checkstyle}\cite{checkstyle}.

\section{Splint}
\label{sec:splint}

Splint is a tool for ``statically checking C programs for security vulnerabilities and programming 
mistakes"\cite[p.\ 9]{splint-manual}. It works exactly as \programName does from the user's
perspective, i.e.\ as a command-line program which prints warnings and errors to \lstinline{stdout}. 
Splint displays warnings about basic semantic errors like assignments with mismatched types and 
ignored return values. With more effort, programmers can add annotations (i.e.\ fancy comments) that 
give Splint a specification to check against. These annotations allow for stronger checks like memory 
management, null pointers and ``violations of information hiding''\cite[p. 9]{splint-manual}. An 
example of annotations in action are the following abstract type declarations (\autoref{splint-annotations}).

\begin{figure}
\begin{lstlisting}[frame=single, language=C]
typedef /*@abstract@*/ /*@mutable@*/ char *mstring;
typedef /*@abstract@*/ /*@immutable@*/ int weekDay;
\end{lstlisting}
\caption[Splint Annotations]{Splint Annotations which define \lstinline{mstring} and \lstinline{weekDay} as abstract types and further specify that they are mutable\slash immutable respectively.} 
\label{splint-annotations}
\end{figure}

While these annotations provide an extensive feature set, they are a huge inconvenience. They 
require programmers to specifically write their code to meet the specification, not only of the client, but 
also of the tool. For new programmers (often the ones who need the most error checking), these 
annotations are almost impossible to implement on top of learning to program, as suggested by  
David Evans (one of the authors) in a private email. He states:
\begin{quote} \singlespacing
One of the goals of the original design of 
Splint was for programmers who add no annotations to start getting some useful warnings right away, 
including warnings that encourage them to start adding annotations.  For some aspects, such as 
\lstinline{/*@null@*/} annotations I think this has worked okay, but for others like abstract types, 
memory management, etc. I don't think it has worked very well, and the warnings on these issues tend 
to either make developers want to stop using Splint, or at least just turn off all the warnings of that type, 
rather than start adding the annotations needed to enable better checking.\cite{evans-email} 
\end{quote}

While they may behave similarly, Splint and \programName are completely different. The biggest 
difference is their realms of inspection. Splint checks the ``correctness'' of code, allowing for bug 
prevention and refactoring. These checks for correctness sometimes provide semantic error checking as 
well when the errors themselves overlap (``correctness'' can often be about how something should be as 
opposed to strictly incorrect code). \programName checks the style of code which makes it more
readable, indirectly allowing for bug prevention and refactoring. They also differ in how they specify what 
to check. Splint uses a configuration file and command line arguments to determine which of the several 
hundred pre-defined messages and warnings to display. In contrast, \programName allows an 
administrator to write their own checks and always runs every check that is defined.

\section{PMD and Checkstyle}
\label{sec:pmdAndCheckstyle}

PMD is a tool for checking Java code that is integrated into a dozen or so different popular IDEs.
PMD comes pre-made with over 250 checks broken up mostly by purpose such as Braces Rules, 
Basic Rules, Coupling Rules, etc. Some checks also deal explicitly with a certain 
library or platform like Android, Jakarta and JUnit. PMD functions by passing source code into a 
JavaCC-generated parser and receiving an Abstract Syntax Tree (a.k.a.\ AST, a tree-based model of 
the source code). PMD then traverses the AST and calls each rule in the RuleSet to check for any
violations. This pattern of examining a tree of nodes is called the Visitor Pattern\cite{design-patterns}. 
The RuleSet is an XML file that can be edited to augment the functionality of PMD with customized 
rules. Rules are written in their own classes and extend a base implementation. The rule itself can 
override three functions (start, visit and end) to perform various checks against the source code based 
on the nodes in the AST. The ``dummy'' example from the PMD website which counts how 
many expressions are in the source code is shown in \autoref{pmd-rule}.

\begin{figure}
\begin{lstlisting}[language=Java]
package net.sourceforge.pmd.rules;

import java.util.concurrent.atomic.AtomicLong;
import net.sourceforge.pmd.AbstractJavaRule;
import net.sourceforge.pmd.RuleContext;
import net.sourceforge.pmd.ast.ASTExpression;

public class CountRule extends AbstractJavaRule {

	private static final String COUNT = "count";

	@Override
	public void start(RuleContext ctx) {
		ctx.setAttribute(COUNT, new AtomicLong());
		super.start(ctx);
	}

	@Override
	public Object visit(ASTExpression node, Object data) {
		// How many Expression nodes are there in all files parsed! 
		RuleContext ctx = (RuleContext)data;
		AtomicLong total = (AtomicLong)ctx.getAttribute(COUNT);
		total.incrementAndGet();
		return super.visit(node, data);
	}

	@Override
	public void end(RuleContext ctx) {
		AtomicLong total = (AtomicLong)ctx.getAttribute(COUNT);
		addViolation(ctx, null, new Object[] { total });
		ctx.removeAttribute(COUNT);
		super.start(ctx);
	}
}
\end{lstlisting}
\caption[Example PMD Rule]{Example PMD rule which counts the number of expressions in the source code.}
\label{pmd-rule}
\end{figure}

Checkstyle provides similar functionality to PMD in that it checks Java code for semantic errors.  It was 
designed to help programmers adhere to coding standards and later developed checks for bug 
prevention, class design problems, etc. Accordingly, Checkstyle provides different checks out of the box 
(namely those regarding duplicate code, class design, whitespace, etc.). Like PMD, it uses an AST and 
the Visitor Pattern to check code. Custom rules are registered through an XML file and passed to 
Checkstyle at runtime. An example check which determines how many methods are in a class is shown 
in \autoref{checkstyle-rule}.

\begin{figure}
\begin{lstlisting}[language=Java]
package com.mycompany.checks;
import com.puppycrawl.tools.checkstyle.api.*;

public class MethodLimitCheck extends Check
{
    private static final int DEFAULT_MAX = 30;
    private int max = DEFAULT_MAX;

    @Override
    public int[] getDefaultTokens()
    {
        return new int[]{TokenTypes.CLASS_DEF, TokenTypes.INTERFACE_DEF};
    }

    @Override
    public void visitToken(DetailAST ast)
    {
        // find the OBJBLOCK node below the CLASS_DEF/INTERFACE_DEF
        DetailAST objBlock = ast.findFirstToken(TokenTypes.OBJBLOCK);
        
        // count the number of direct children of the OBJBLOCK that 
        // are METHOD_DEFS
        int methodDefs = objBlock.getChildCount(TokenTypes.METHOD_DEF);
        
        // report error if limit is reached
        if (methodDefs > this.max) {
            log(ast.getLineNo(),
                "too many methods, only " + this.max + " are allowed");
        }
   }
}
\end{lstlisting}
\caption[Example Checkstyle Check]{Example Checkstyle check which counts the number of methods in a class.}
\label{checkstyle-rule}
\end{figure}

PMD and Checkstyle are great tools and have been integrated into many popular IDEs. However, 
because they only work for Java, they do not satisfy my problem: semantic error checking in C. In 
essence PMD\slash Checkstyle and \programName perform very similarly; however, they are built upon 
entirely different frameworks. The use of the Visitor Pattern and an AST requires PMD and Checkstyle to 
read though the entirety of the code before they can produce any errors. In contrast, \programName 
performs error checking as the code is read. PMD and Checkstyle also contain graphical user interfaces 
both to aid writing checks and to find errors (the latter due to their integration with IDEs). \programName, 
on the other hand, produces textual errors from the command line. Furthermore, the \programName must 
be recompiled to take advantage of new checks as opposed to responding at runtime to a configuration 
file.

\chapter{What \programName Does}

\programName reads in a set of C source code files and determines if they contain any of the 
specified semantic errors. It is run through the command line inside one's 
working directory. \programName is given a list of .c files to check and reads through each in the 
given order, stopping to read through any locally included header files. Upon encountering an error,
\programName prints out the full location of the error, a warning level and an error message to 
\lstinline{stderr} (an example is shown in \autoref{errorExample}). 

\begin{figure}
\begin{subfigure}[b]{.49\linewidth}
\caption{test.c}
\label{errorExampleCode}
\begin{lstlisting}[numbers=left, firstnumber=92, xleftmargin=.8cm]
	for (int q = 0; q<5; q++) {
		printf("hi");
	}
\end{lstlisting}
\end{subfigure}
\begin{subfigure}[b]{.49\linewidth}
\caption{stderr}
\label{errorExampleStderr}
\begin{lstlisting}[xleftmargin=.7cm]
$ critTer test.c
test.c:92.22-92.23: big problem: Do not use magic numbers
\end{lstlisting}
\end{subfigure}
\caption[Example Error and Corresponding Message]{Example Error and Corresponding Message. Here, \programName is complaining that the for loop's exit condition contains a `magic number', in this case `5'. The error message contains the location of the error, the warning level and then the error message.}
\label{errorExample}
\end{figure}
\todo{used word critTer here}

The administrator is responsible for defining the set of checked semantic errors. \programName 
comes with a set of predefined checks that the administrator may use or discard at their discretion. 
Checks are event driven and are called when the appropriate element in the code is reached. For 
example, checking for a minimum length of each variable name happens when \programName 
recognizes a variable inside a declaration. The administrator can write their own checks as functions 
to be invoked at each of the relevant callback points.

The set of predefined checks are listed below in \autoref{predefinedChecks}. These checks reflect 
two main purposes: demonstration of the various abilities of \programName and my own arbitrary style 
choices. In order to show off some of the power of \programName, I wrote a variety of checks that show 
the various distinct elements that can be examined. Some checks, like isFunctionTooLongByLines and 
isFunctionTooLongByStatements, are really two different implementations of the same check. The style 
choices I made represent ideas from a variety of sources including Fowler's Bad Smells of 
Code\cite{refactoring}, Google's style guide\cite{googleStyle}, Code Complete\cite{code-complete}, 
C-Style: Standards and Guidelines\cite{standards} PMD\cite{pmd} and Checkstyle\cite{checkstyle}, as 
well as my own experience.

\begin{table}
\small
	\begin{center}
	\begin{tabular}{l p{9cm}}
		\toprule
		Check Name & Purpose \\
		\midrule
		isFileTooLong & Check if the file exceeds a maximum length. \\
		hasBraces & Check if there are braces surrounding an \lstinline!if!, \lstinline!else!, \lstinline!for!, \lstinline!while! and \lstinline!do while! statement. \\
		isFunctionTooLongByLines & Check if a function exceeds a maximum line count. \\
		isFunctionTooLongByStatements & Checks if a function exceeds a maximum statement count. \\
		tooManyParameters & Check if there are too many parameters in the function declaration. \\
		CPlusPlusComments & Throw an error on C++ style single line comments. \\
		checkForComment & Check for comments before some construct. \\
		switchHasDefault & Check that each \lstinline!switch! statement has a \lstinline!default! case. \\
		switchCasesHaveBreaks & Check that each \lstinline!switch! case has a \lstinline!break! statement. \\
		tooDeeplyNested & Check whether a region of code (i.e. a compound statement) nests too deeply. \\
		useEnumNotDefine & Advises using \lstinline!enum! instead of \lstinline!#define! for declarations. \\
		neverUseGotos & Throw an error on any use of a \lstinline!GOTO! statement. \\
		isVariableNameTooShort & Check if a variable's name exceeds a minimum length. \\
		isMagicNumber & Throw an error on encountering a magic number outside of a declaration. \\
		globalHasComment & Check if each global variable has a comment. \\
		isLoopTooLong & Check if the loop length exceeds a maximum length. \\
		isCompoundStatementEmpty  & Check if the compound statement is empty. \\
		tooManyFunctionsInFile & Check if there are too many functions in a file. \\
		checkIfElsePlacement & Throw an error based on the placement of the else statement relative to the if statement.  \\
		validateComment & Check if function comments have the appropriate contents. Specifically check that the comment mentions each parameter (by name) and what the function returns. \\
		validatePointerParameters & Check if each pointer type parameter into a function is mentioned within an \lstinline!assert()! before being used. \\
		doFunctionsHaveCommonPrefix & Check that function names contain a common prefix. \\
		functionHasEnoughLocalComments & Check that there are enough local comments in the function relative to the number of control/selection statements. \\
		structFieldsHaveComments & Check that all fields in a struct have a comment. \\
		\bottomrule
	\end{tabular}
	\end{center}
\caption{Predefined Checks}
\label{predefinedChecks}
\end{table}

\chapter{How \programName Works}
\label{howItWorks}

\autoref{moduleInteraction} shows how \programName is divided up into multiple semi-autonomous 
modules. Each of these has a unique function and is designed to keep the code as clean as possible. 
The ``Knowledge Barrier'' distinguishes the easily customizable and understandable modules from 
those which should not be modified without extreme caution. These modules in turn can be 
conceptually grouped into three categories: \hyperref[parsingTheCode]{Parsing the Code}, 
\hyperref[howChecksAreCalled]{How Checks are Called} and 
\hyperref[howChecksAreWritten]{How Checks are Written}.

\begin{figure}[h!]
\begin{center}
\processifversion{PRINT}{\includegraphics[scale=0.6]{ClassInteractionPrint}}
\processifversion{COLOR}{\includegraphics[scale=0.6]{ClasInteractionColor}}
\end{center}
\caption{Module Interaction of \programName}
\label{moduleInteraction}
\end{figure}

\section{Parsing the Code}
\label{parsingTheCode}

\programName is built on top of Bison and Flex, a parser generator and a lexical analyzer 
respectively. These two programs each take in a specification file (which define a set of tokens and a 
corresponding context free grammar) and output a set of C files to dynamically parse code. 
Control goes back and forth between the lexical analyzer, which recognizes code as distinct elements, 
and the parser, which determines how the elements fit together. \programName's specification files 
describe valid ANSI C code but \programName does not compile or in anyway track the contents. This 
means, for example, that \programName sees any variable or function name as just as an 
\lstinline{IDENTIFIER} (any set of letters that does not already designate a variable type) without any 
context as to where it was defined or used before. Because \programName cannot evaluate code, it 
cannot follow preprocessor directives. \programName therefore reads all of the code in the file, even if 
it would not actually be included during compilation. In order to combat the issue of multiple inclusion 
of header files, \programName stores the name of each file it opens and does not open that file again, 
even if it is included from another file. Standard header files (such as \lstinline{stdlib.h} and 
\lstinline{strings.h}) are not read because they define types within preprocessor directives (which 
\programName cannot evaluate and therefore cannot recognize as a type). To adjust for this issue, the 
lexer instead contains a hack for determining if character strings in the code are \lstinline{IDENTIFIER}s 
or type names. Namely, the lexer does a string comparison against common types defined in standard 
headers such as \lstinline{size_t}, \lstinline{FILE}, \lstinline{pid_t}, etc. If any of these hardcoded checks 
pass, then the lexer tells the parser it has found a type name instead of an \lstinline{IDENTIFIER}.

Bison and Flex track the location of any token or grammar construct. They store 
this information in a \lstinline{YYLTYPE} structure. (Normally a \lstinline{YYLTYPE} contains 4 fields, 
\lstinline{first_line}, \lstinline{first_column}, \lstinline{last_line} and \lstinline{last_column}; however, I 
have also added a \lstinline{filename} field in order to produce more accurate checks and error 
messages across a set of files.) Each grammar rule can contain multiple actions which consist of C code. 
These actions can reference the location of the entire rule, or any of single component of it, through this 
prebuilt location mechanism. \programName calls the event handlers from these actions, passing in 
the location of the relevant construction (see \autoref{grammar}, where actions are underlined). 
Some actions are `hidden' in subroutines in order to avoid ambiguities within the grammar. Locations 
passed from the middle of a rule (all the ones passed to \lstinline{begin} handlers) only represent the 
location of that segment as opposed to the entire construct. For example, in \autoref{grammar}, 
\lstinline{beginIf} will only be passed the location of the word ``\lstinline{if}'' whereas 
\lstinline{endIf} will be passed the location of the entire \lstinline{if} statement.

\begin{figure} 
\begin{lstlisting}[language=Caml, escapechar=\%]
parameter_list
	: parameter_declaration											%\underline{\{h\_registerParameter(@\$);\}}%
	| parameter_list ',' parameter_declaration	%\underline{\{h\_registerParameter(@3);\}}%
	;

parameter_declaration
	: declaration_specifiers declarator
	| declaration_specifiers abstract_declarator
	| declaration_specifiers
	;

beginIF : /*empty*/ %\underline{\{beginIf(@\$);\}}%

selection_statement
	: IF beginIF '(' expression ')' statement %\underline{\{endIf(@\$);\}}%
	| IF beginIF '(' expression ')' statement ELSE %\underline{\{endIf(@6); beginElse(@7);\}}% statement	%\underline{\{endElse(@9);\}}%
	| SWITCH %\underline{\{beginSwitch(@1);\}}% '(' expression ')' statement %\underline{\{endSwitch(@\$);\}}%
	;

beginFOR : /*empty*/ %\underline{\{beginFor(@\$);\}}%

iteration_statement
	: WHILE %\underline{\{beginWhile(@1);\}}% '(' expression ')' statement %\underline{\{endWhile(@\$);\}}%
	| DO %\underline{\{beginDoWhile(@1);\}}% statement WHILE '(' expression ')' ';' %\underline{\{endDoWhile(@\$);\}}%
	| FOR beginFOR '(' expression_statement expression_statement ')' statement	%\underline{\{endFor(@\$);\}}%
	| FOR beginFOR '(' expression_statement expression_statement expression ')' statement %\underline{\{endFor(@\$);\}}%
	| FOR beginFOR '(' declaration expression_statement ')' statement %\underline{\{endFor(@\$);\}}%
	| FOR beginFOR '(' declaration expression_statement expression ')' statement	%\underline{\{endFor(@\$);\}}%

\end{lstlisting}
\caption{Excerpt of the Grammar}
\label{grammar}
\end{figure} 

Instead of writing them from scratch, I found the Flex and Bison specification files 
online\cite{originalGrammar} and have modified them to add additional functionality. The only major 
modification of the actual grammar was to add the ability to recognize and dynamically add 
\lstinline{typdef} definitions as types. These type names are stored in an internal symbol table and the 
lexer checks to make sure that any potential \lstinline{IDENTIFIER}s are not already listed there. In 
order to accommodate the inclusion of header files, I had to expand the given lexer functionality to 
transfer control between files. The specific method of using a stack of buffers\slash files is heavily 
inspired from the examples in the O'Reily Flex \& Bison book\cite{flex-and-bison}. When transferring to a 
different file, the lexer adds the current file to a stack with its file pointer, internal state, and current line 
number. When it reaches the end of the file, the lexer pops the current file off the stack and goes back 
to its previous state. The end of program occurs when there are no more files on the 
stack.\footnote{\programName starts by adding all of the given files to the stack and dynamically adding 
additional header files. While this pre-loading is not strictly in concordance with the model of adding 
header files, it simplified the interface between the main module and the lexer\slash parser.

Additionally, the lexer reads in header filenames without any additional context about the path of the 
current file. Because of this, \programName is unable to find and read header files that are included from 
within subdirectories. It is relatively rare within an academic context to break a single program into 
subdirectories and accordingly I decided not to focus on this issue.} 

\section{How Checks are Called}
\label{howChecksAreCalled}

\programName is event based and is largely inspired by SAX\cite{saxHomepage}. SAX is a 
framework which allows programmers to use event handlers to parse XML files. SAX typically uses
event handlers for the beginning and end of each XML element as well as to capture the text in 
between. \programName calls event handlers at the beginning and end of constructs (functions, 
declarations, statements, parameter lists, etc.) as well as when it finds singular elements (variable 
names, \lstinline{break} statements, parameters, etc.). In the code, handlers are prefaced by the words 
``\lstinline{begin}'', ``\lstinline{end}'' and ``\lstinline{register}'' to signal at what point each is called (as 
shown in \autoref{grammar}). Each handler is passed, at minimum, the location of the relevant code (in 
the case of \lstinline{IDENTIFIER}s and numeric constants, the handler is also passed the relevant 
text). Each of these event handlers exist in the file sax.c/h which in turn call the administrator defined 
checks. While these checks could be written into the event handlers themselves, it is conventional to 
separate them into their own functions (and files) in order to preserve the readability of the sax.c file 
and the code in general. A list of predefined checks, their function signatures and the handlers which 
call them are listed in \autoref{predefinedChecksFunctions}.

Unfortunately some handlers cannot actually be called at the time the construction is recognized. This 
is due to the fact that Bison executes actions as they are encountered inside each grammar rule. At the 
beginning of a rule, Bison would not know which rule it was actually matching when it needed to 
execute the action. In all the rules listed in \autoref{grammar}, the action is preceded by some 
distinguishing token (like \lstinline{WHILE}) or by the entire rule. However, \autoref{hookGrammar} 
shows some rules that both need actions at the beginning of the statement and lack distinguishing 
tokens. Specifically we would like to know when we start the beginning of a function definition, but we 
cannot be sure that we are in a function definition until Bison finishes parsing the signature. To fix this 
issue I have added the Hooks module. This module intercepts what would be normal calls within the 
SAX framework and then reorders them at the appropriate time. Each call into the Hooks module does 
one of two things: enqueues a Sax level function call and its location or dequeues any item after a 
specified location (\autoref{hooksQueues}). With the beginning of a function, all the elements of the 
signature are placed on the queues and then dequeued when \lstinline{h_beginFunctionDefinition} is 
called. Another reason for the hooks module is to make the appropriate calls into the Sax layer 
regarding \lstinline{IDENTIFIER}s and numeric constants. Bison only deals with the tokens as opposed 
to their text whereas Flex only deals with the actual text. The hooks module takes separate calls from 
both programs regarding the location and the actual text of \lstinline{IDENTIFIER}s and constants and 
routes them into a combined call in the SAX layer. This can best be seen in \autoref{handlerTimeline}.

The Hooks and Sax modules are not complete. Handlers for major and common constructs, as well as 
the beginning and end of each file and the program, have been implemented. Smaller items, like the 
registration of the different operators and data types, have yet to be implemented. The addition of further 
handlers is very possible although should only be done after fully comprehending how the system 
works. Specifically, it is critical to route handlers through Hooks only when they occur inside statements 
and declarations (as well as anything else which is reordered in Hooks) and through Sax otherwise.

In addition to the basic SAX style system, I have implemented one shortcut to help identify code context 
without an excess of global variables. Every time a handler is called, it sets the 
\lstinline{lastCalledFunction} (through a setter). Checks can then use this variable to easily figure out 
what the previous context was without additional calls or variables.

\begin{figure}
\begin{lstlisting}[language=Caml, escapechar=\%]
declarator
	: pointer direct_declarator
	| direct_declarator
	;

direct_declarator
	: IDENTIFIER			 %\underline{\{h\_registerIdentifier(@\$);\}}%
	| '(' declarator ')'
	| direct_declarator '['  %\underline{\{h\_beginDirectDeclarator(@1);\}}% constant_expression ']'	 %\underline{\{h\_endDirectDeclarator(@\$);\}}%
	| direct_declarator '['  %\underline{\{h\_beginDirectDeclarator(@1);\}}% ']'						%\underline{\{h\_endDirectDeclarator(@\$);\}}%
	| direct_declarator '('  %\underline{\{h\_beginDirectDeclarator(@1);\}}% parameter_type_list ')'	%\underline{\{h\_endDirectDeclarator(@\$);\}}%
	| direct_declarator '('  %\underline{\{h\_beginDirectDeclarator(@1);\}}% identifier_list ')'		%\underline{\{h\_endDirectDeclarator(@\$);\}}%
	| direct_declarator '('  %\underline{\{h\_beginDirectDeclarator(@1);\}}% ')'						%\underline{\{h\_endDirectDeclarator(@\$);\}}%
	;


function_definition
	: declaration_specifiers declarator %\underline{\{h\_beginFunctionDefinition(@2);\}}% declaration_list compound_statement %\underline{\{endFunctionDefinition(@\$);\}}%
	| declaration_specifiers declarator %\underline{\{h\_beginFunctionDefinition(@2);\}}%} compound_statement %\underline{\{endFunctionDefinition(@\$);\}}%
	| declarator %\underline{\{h\_beginFunctionDefinition(@1);\}}% declaration_list compound_statement %\underline{\{endFunctionDefinition(@\$);\}}%
	| declarator %\underline{\{h\_beginFunctionDefinition(@1);\}}% compound_statement %\underline{\{endFunctionDefinition(@\$);\}}
	;
\end{lstlisting}
\caption{Additional Excerpt of the Grammar}
\label{hookGrammar}
\end{figure}

\begin{figure}
\begin{center}
\begin{subfigure}[t]{.4\linewidth}
	\caption{}
	\label{hooksQueuesA}
	\includegraphics[scale=0.5]{hooksQueuesPartA.pdf}
\end{subfigure}
\begin{subfigure}[t]{.4\linewidth}
	\caption{}
	\label{hooksQueuesB}
	\includegraphics[scale=0.5]{hooksQueuesPartB.pdf}
\end{subfigure} \\
\vspace{4mm}
\begin{subfigure}[t]{.4\linewidth}
	\caption{}
	\label{hooksQueuesC}
	\includegraphics[scale=0.5]{hooksQueuesPartC.pdf}
\end{subfigure}
\begin{subfigure}[t]{.4\linewidth}
	\caption{}
	\label{hooksQueuesD}
	\includegraphics[scale=0.5]{hooksQueuesPartD.pdf}
\end{subfigure}
\end{center}
\caption[Representation of the Hooks Module]{Representation of the Hooks Module. \\(\subref{hooksQueuesA}) The initial queue with functions associated to locations 11, 12 and 13. \\(\subref{hooksQueuesB}) The queue after another function\slash location pair has been enqueued. \\ (\subref{hooksQueuesC}) The call at location 15 causes a call into the Sax layer followed by every stored call after the given location (12) in the queue. \\ (\subref{hooksQueuesD}) The resulting queue.}
\label{hooksQueues}
\end{figure}

\begin{figure}
\begin{center}
\begin{tabular}{llc}
\toprule
Hooks & Sax  & Relevant Code\\
\midrule
h\_registerIdentifierText & & \lstinline!example! \\
h\_registerIdentifier & & \lstinline!example! \\
h\_beginParameterList & & \lstinline!(! \\
h\_registerIdentifierText & & \lstinline!a! \\
h\_registerIdentifier & & \lstinline!a! \\
h\_registerParameter & & \lstinline!int a! \\
h\_registerIdentifierText & & \lstinline!b! \\
h\_registerIdentifier & & \lstinline!b! \\
h\_registerParameter & & \lstinline!double b! \\
h\_endParameterList & & \lstinline!)! \\
h\_beginFunctionDefinition & beginFunctionDefinition & \\
 & registerIdentifier & \lstinline!example! \\
 & beginParameterList & \lstinline!(! \\
 & registerIdentifier & \lstinline!a! \\
 & registerParameter & \lstinline!int a! \\
 & registerIdentifier & \lstinline!b!\\
 & registerParameter & \lstinline!double b!\\
 & endParameterList & \lstinline!)!\\
N/A & beginCompoundStatement & \lstinline!{!\\
\ldots & \ldots & \lstinline!...! \\
N/A & endCompoundStatement & \lstinline!}!\\
N/A & endFunctionDefinition \\
 \bottomrule
\end{tabular}
\end{center}
\caption[Timeline of Event Handler Calls]{Timeline of event handler calls into the hooks and sax module for: \lstinline!void example(int a, double b) \{...\}!}
\label{handlerTimeline}
\end{figure}
\newpage

\section{How Checks Are Written}
\label{howChecksAreWritten}

Minimally, each check needs access to the location of the code construct in order to be able to produce 
an error. However, checks often need additional information regarding the surrounding context of 
the possible error. A simple example is the check against using magic numbers 
(\autoref{checkWithContext}). Many programmers consider using numeric constants directly inside the 
code very poor style and recommend defining a variable to hold that value. Therefore \programName 
should only throw an error when it finds an magic number inside a normal statement (as opposed to 
inside a declaration where it is necessarily defined). This check then needs to know every time a 
declaration begins and ends as well as each time a number is found. Alternatively, one can set global 
variables regarding the context and minimize the number of parameters to each check.

\newcommand{\yyerror}{\lstinline{yyerror}\xspace}
\newcommand{\lyyerror}{\lstinline{lyyerror}\xspace}
\newcommand{\lyyerrorf}{\lstinline{lyyerrorf}\xspace}

In order to throw an error, the administrator can use one of three error functions: \yyerror, \lyyerror, and 
\lyyerrorf. Each of these functions outputs an error message to \lstinline{stderr} preceded by the error's 
location in the code and a warning level (as seen in \autoref{errorExample}). \yyerror and \lyyerrorf 
are each wrappers to \lyyerror, which takes in an error level (\lstinline{enum errorLevel}), a location 
(\lstinline{YYLTYPE}) and an error message (\lstinline{char *}). In essence, \lyyerror is really a wrapper 
to \lstinline{fprintf} and defines the formatting of all the error messages\slash locations. It is also the 
location to change the string value of the different error levels.\footnote{Currently, 
\lstinline{ERROR_HIGH}=``big problem'', \lstinline{ERROR_NORMAL}=``error'', and 
\lstinline{ERROR_LOW}=``low priority''.}  
\lyyerrorf, instead of taking in an error message, takes a format string and a variable argument list, 
which it uses with \lstinline{vsprintf} to create an error message. It then passes the newly created 
message to \lyyerror with the rest of its arguments. \yyerror only takes an error message and calls 
\lyyerror with Bison's internal location in the code and a default high error level. This is because 
\yyerror is called internally through Bison to represent syntax errors. \yyerror is the only predefined 
error reporting function; \lyyerror is an extension suggested by O'Reily\cite{flex-and-bison} when using 
location tracking with Bison\slash Flex (the `l' represents the variable location). \lyyerrorf was created in 
the likes of \lstinline{printf} to deal with formatted error messages in one consolidated function.

\begin{figure}
\begin{lstlisting}[language=C]
void isMagicNumber(YYLTYPE location, int progress, char* constant) {
	int acceptableNumbers[3] = {0, 1, 2};
	int numAcceptable = sizeof(acceptableNumbers)/sizeof(int);

	static int inDeclaration = 0;
	
	switch (progress) {
		case BEGINNING:
			inDeclaration++;
			break;
		case MIDDLE:
			if (inDeclaration == 0) {
				int number = (int)strtol(constant, (char**)NULL, 0);
				int i;

				/* see if number is within the acceptableNumbers array */
				for (i = 0; i < numAcceptable; i++) {
					if (number == acceptableNumbers[i]) {
						return;
					}
				}
				lyyerror(ERROR_HIGH, location, "Do not use magic numbers");
			}
			break;
		case END:
			inDeclaration--;
			break;
		default:
			break;
	}
}
\end{lstlisting}
\caption[\programName Check with Additional Context]{\programName check with additional context that throws an error on encountering a magic number outside of a declaration.}
\label{checkWithContext}
\end{figure}

Additionally, there are two helper modules designed to facilitate writing checks: Locations and 
Comments. The Locations module contains a several functions to manipulate \lstinline{YYLTYPE}s.  
Specifically it contains methods to compare locations in various directions\slash distances as well as 
allocate, copy and free \lstinline{YYLTYPE}s. The Comments module tracks all the comments found 
while running \programName. Comment contents and locations are registered through calls from the 
Sax layer and are stored in a dynamic array. Adjacent comments are recognized and combined into one 
larger comment. Additionally the module provides the ability to search through this array to find 
comments in or near a certain location (using the methods from Locations). Finally Comments provides a 
couple of useful functions when analyzing the comment itself: determining if a comment has words (as 
opposed to a delimiting comment in the form of \lstinline{/*----*/} etc.) and if a comment contains a string 
(with or without case sensitivity).

There are some coding styles which are very hard for \programName to check. For example, when 
checking that each global variable has a comment, it is trivial to check if there is a comment before that 
declaration. However, if the comment appears after the declaration (as is common in some header 
files), \programName is unable to find the comment. This is because \programName, at the end of a 
declaration, has not read or stored the following comment. There are two solutions to this issue. The 
first is a creative hack in which one stores every location of a global variable and then searches for 
comments after each location at the end of the file. The second and preferred solution is to change the 
coding standard to have comments precede declarations.

\chapter{How to Use \programName}

\section{Users}
Find out from your administrator where you should find their version of \programName. After following 
their installation instructions, go to your working directory from the command line. Type 
``\lstinline{critTer *.c}'' (or if you only want to check one or two files, type their names instead of the 
\lstinline{*.c}). \todo{used the word critTer here!!} \programName will output 
any warnings about your code to \lstinline{stderr}.

\section{Administrators}

\subsection{Use}
In academics, the best use of \programName is as an automated grading system. It is simple to assign a 
point reduction system based on the number of errors \programName returns over a submission. For 
example, one might deduct a two point penalty per high error level message, a point per normal error 
level message and a half a point per low error level message. Not only does it reduce the work needed 
to grade a submission, but by allowing students to pre-check their work, the submissions become easier 
to read through good, consistent style.

In industry, \programName should be used by programmers before submitting code to a repository or to 
peer reviews. This creates and automated reminder system against any code that does not adhere to the 
accepted coding standards. This makes the code base more consistent and readable without direct 
peer enforcement. Furthermore, the team can be more productive when they spend less time correcting 
semantic errors.

\subsection{Customization}
Before customizing the code, please make sure you both understand how \programName works (see 
\autoref{howItWorks}) and have looked through the Code 
Conventions in \autoref{conventions}).

\subsubsection{Add a Check}

The first step of adding a new semantic check is to figure out what exactly you are checking and which 
handlers give you the necessary information. The first question to ask is how much context is needed to 
implement this check. For example, to throw an error on C++ style comments requires no context -- it is 
only dependent on the existence of that code. In contrast, checking for braces around \lstinline{for} loops 
requires very minimal context: whether or not \lstinline{endCompoundStatement} was the last function 
called (i.e. right before \lstinline{endFor} was called, did \programName encounter a `\lstinline!}!' or 
something else). This minimal context can be established through the use of the 
\lstinline{lastCalled_get()} function which returns a pointer to the last Sax handler called. More complex 
checks may need additional context. For example, to check for magic numbers, the check needs to keep 
track of whether the numeric constant appears inside a declaration. The easiest way to do this is to have 
the check called from \lstinline{registerConstant}, \lstinline{beginDeclaration} and 
\lstinline{endDeclaration} and pass in a different `progress' value at each different call. Throughout the 
code, the enumerated values \lstinline{BEGINNING}, \lstinline{MIDDLE} and \lstinline{END} provide 
such values.

After determining the relevant handlers and additional necessary parameters,\footnote{Each check 
should have at least one parameter: \lstinline{YYLTYPE location}. This value is necessary in order to 
produce a proper error message. All other parameters are optional and should follow \lstinline{location}. 
Many checks can be completed using only a progress value or informative string.} one must actually 
write the check. The easiest way to deal with contextual processing is to use a \lstinline{switch} 
statement and conditionally set static local variables (\autoref{addCheckExample}). In order to 
throw an error, one must pass \lstinline{location} to either \lstinline{lyyerror} or \lstinline{lyyerrorf} with an 
error level and either an error message or format string and arguments respectively (for additional 
information see \autoref{howChecksAreWritten}).

\begin{figure}
\begin{lstlisting}[language=C]
/**
 * Check that each switch statement has a default case.
 */
void switchHasDefault(YYLTYPE location, int progress) {
	static int started = 0;
	static int found = 0;
	
	switch (progress) {
		case BEGINNING:
			started = 1;
			found = 0;
			break;
		case MIDDLE:
			found = 1;
			break;
		case END:
			if (!found && started) {
				lyyerror(ERROR_HIGH, location, 
					       "Always include a default in switch statements");
			}
			started = 0;
			break;
		default: 
			break;
	}
}
\end{lstlisting}
\caption[\programName Check with Contextual Processing]{\programName Check with Contextual Processing. \lstinline{switchHasDefault} is called from \lstinline{beginSwitch} with \lstinline{BEGINNING}, \lstinline{endSwitch} with \lstinline{END} and \lstinline{registerDefault} with \lstinline{MIDDLE}.}
\label{addCheckExample}
\end{figure}

\subsubsection{Add an Event Handler}

If you want to add an event handler, be advised, you will have to edit the grammar file. If you screw up 
this file, it will break \programName. Having said that, creating a handler is actually quite trivial assuming 
you are careful. The first step is to figure out which grammar rule(s) are relevant to the event you would 
like to capture. In some cases this is incredibly trivial, in others it takes some effort to understand what the 
grammar is describing. The best method to figure out the various rules is, in my experience, to perform 
DFS through the different components of the rule until it becomes clear. 

After finding the grammar rule, adding a \lstinline{register} or \lstinline{end} handler is very simple: 
define the handler in sax.c/h and add the action ``\lstinline!{newHandler(@X);}!'' after the component you 
want to recognize. The \lstinline{@X} references the location of either the component (where \lstinline{X} 
= the number of the component) or the entire rule (where \lstinline{X} = `\lstinline{$}'). \autoref{grammar}
 and \autoref{hookGrammar} show examples of these calls. Unfortunately adding 
\lstinline{begin} handlers can be much more difficult than the previous cases although, in principle, the 
process is identical. This is due to the possibility of adding ambiguities to the grammar. When this 
happens, Bison will throw several errors during compilation and the parser will most likely break. The 
first tactic to avoid this issue is to never have actions as the first element in a rule; they should always 
appear after (at least) one component. If this approach is insufficient, you should try burying the 
action inside a subroutine (like \lstinline{beginFOR} and \lstinline{beginIF} in \autoref{grammar}).

There are only two reasons to route your new handler through the Hooks module instead of going 
directly to Sax; the most likely reason is the event occurs inside a construct that already goes through 
Hooks. Declarations, function signatures, and statements currently go through Hooks. This means that 
events like \lstinline{registerConst} must also go through Hooks in order to be released to Sax at the right 
time (see \autoref{howChecksAreCalled}). The second motive is the reason why those constructs 
already go through Hooks:  it is the the only way of getting an accurate \lstinline{begin} handler. By this I 
mean it is either impossible or very hard\slash complicated to create a \lstinline{begin} handler in the 
right spot in the grammar such that it comes before all its components. These constructs dequeue all the 
appropriate previous calls once the \lstinline{h_endXX} handler is called.

If you do not need to go through Hooks, after defining the action in the grammar file and the handler in 
both sax.c and sax.h, all you need to do is call \lstinline{lastCalled_set()} from the handler. If the new 
handler needs to go through Hooks, you need to create two handlers: \lstinline{newHandler} in Sax and 
\lstinline{h_newHandler} in Hooks (where \lstinline{h_newHandler} is called from the action in the 
grammar file). If the event just needs to be released at the correct time (i.e. it appears within a hooked 
construct), the Hooks handler should call \lstinline{enqueueFunctionAndLocation} to enqueue the Sax 
handler. If the handler needs to dequeue elements, it should call \lstinline{dequeueUntil}, followed by the 
sax handler and \lstinline{lastCalled_set()}.

\subsection{Compilation, Testing and Installation}

\programName contains a Makefile which contains targets for compilation, testing and installation. To 
compile the given version of \programName (or a customized version without additional files), simply 
type ``\lstinline{make}''. To compile \programName with additional files, edit the \lstinline{all} target to 
include the new files and then type ``\lstinline{make}''. To install \programName (i.e. copy into 
\lstinline{/usr/local/bin/}) type ``\lstinline{make install}''.

Testing can be accomplished by typing ``\lstinline{make test}'' which uses two shell scripts to run the 
local version of \programName over a set of test files and then compares the new output to the previous 
output. The first script, \lstinline{runOnTests.sh}, has a set of paths over which to run \programName. The 
error messages are piped to \lstinline{output.txt} after the old output has been copied to 
\lstinline{output_old.txt}. The second script, \lstinline{checkTestOutput.sh}, uses a list of all the error 
messages and \lstinline{grep} to break apart the output files check by check. The script then 
\lstinline{diff}s each section of the files to determine if a check has been broken. In order to add new 
checks to the testing mechanism, one simply needs to add the check's function name and a significant 
(non-variable) part of the error message into the appropriate arrays inside \lstinline{runOnTests.sh}.

\chapter{Evaluation}

In order to perform a realistic evaluation of \programName's performance, Dr. Robert Dondero, graded 
10 randomly chosen final project submissions for Princeton University's Introduction to Programming 
Systems (COS 217) \cite{cos217}. There were over 650 assignments available, each of which was 
anonymized in order to protect student's privacy. Dr. Dondero has taught the course for many years, 
making him the perfect person to judge each submission's style. We judged \programName's 
performance compared to ``true'' errors, which were determined after both Dr. Dondero and 
\programName looked at each submission. This post-analysis judgement of errors was necessary in 
order to properly take into account errors that Dr. Dondero originally missed that \programName found. 
We did allow \programName to perform an iterative analysis of the submissions as a whole, mirroring 
what we hoped other administrators would do when creating their set of checks. The iterative process 
mostly effected checks like \lstinline{fileIsTooLong} or \lstinline{tooDeeplyNested} where there was a 
maximum/minimum threshold that needed to be tuned. 

The raw numbers regarding \programName's performance as compared to Dr. Dondero's are shown in 
\autoref{evalRawNumbers}. These numbers yield a precision rate of !!!! for \programName and !!!! for Dr. 
Dondero. However, these raw numbers count stylistic flaws that \programName does not currently have 
checks for (like excessively long lines and repeat definitions of \lstinline{struct}s). After adjusting for these 
types of errors, \programName performed with a precision rate of !!!! and Dr. Dondero with !!!! (as seen 
from the numbers in \autoref{evalAdjustedNumbers}).


\begin{table}
\begin{center}
\begin{tabular}{cccc}
	\toprule
	& Dr. Dondero & \programName & Total \\
	\midrule
	Error & !!!!! &  !!!!! & !!!!! \\
	Not an Error & 0 & !!!!! & N\slash A \\
	\bottomrule
\end{tabular}
\end{center}
\caption{The raw number of warnings produced by \programName in comparison to Dr. Dondero}
\label{evalRawNumbers}
\end{table}


\begin{table}
\begin{center}
\begin{tabular}{cccc}
	\toprule
	& Dr. Dondero & \programName & Total \\
	\midrule
	Error & !!!!! &  !!!!! & !!!!! \\
	Not an Error & 0 & !!!!! & N\slash A \\
	\bottomrule
\end{tabular}
\end{center}
\caption{The adjusted number of warnings produced by \programName in comparison to Dr. Dondero after removing !!!!!!}
\label{evalRawNumbers}
\end{table}



\vspace{2cm}
 \todoin{Add how \programName performed against Dondero's grading}

\appendix
\appendixpage
\addappheadtotoc

\singlespacing

\chapter{Predefined Check Functions and their Relevant Event Handlers}
 \label{predefinedChecksFunctions}
\newcommand{\saxColSize}{6cm}
\newcommand{\vertSize}{3mm}

\addcontentsline{lot}{table}{~\ref{predefinedChecksFunctions} \hspace{4mm}Predefined Check Functions and their Relevant Event Handlers}
\begin{longtable}{p{10cm} p{\saxColSize}}
\toprule
Check Function \& Purpose & Relevant Sax Handlers \\ \midrule
\endfirsthead
\toprule
Check Function \& Purpose & Relevant Sax Handlers \\ \midrule
\endhead
\hline
\multicolumn{2}{c}{Continued}\\
\bottomrule
\endfoot
\bottomrule
\endlastfoot

		\lstinline!isFileTooLong(YYLTYPE location)! & \multirow{2}{\saxColSize}{endFile} \\*
			 Check if the file exceeds a maximum length.  \vspace{\vertSize} \\
		\lstinline!hasBraces(YYLTYPE location, char* construct)! & \multirow{2}{\saxColSize}{endWhile, endDoWhile, endFor, endIf, endElse} \\*
			 Check if there are braces surrounding an \lstinline!if!, \lstinline!else!, \lstinline!for!, \lstinline!while! and \lstinline!do while! statement. \vspace{\vertSize} \\
		\lstinline!isFunctionTooLongByLines(YYLTYPE location)! & \multirow{2}{\saxColSize}{endFunctionDefinition} \\*
			 Check if a function exceeds a maximum line count. \vspace{\vertSize} \\
		\lstinline!isFunctionTooLongByStatements(YYLTYPE location, int progress)! & \multirow{2}{\saxColSize}{beginFunctionDefinition, endFunctionDefinition, endStatement} \\*
			 Checks if a function exceeds a maximum statement count. \vspace{\vertSize} \\
		\lstinline!tooManyParameters(YYLTYPE location, int progress)! & \multirow{2}{\saxColSize}{beginParameterList, registerParameter, endParameterList} \\*
			 Check if there are too many parameters in the function declaration. \vspace{\vertSize} \\
		\lstinline!CPlusPlusComments(YYLTYPE location)! & \multirow{2}{\saxColSize}{N/A (Called from the Lexer)} \\ *
		Throw an error on C++ style single line comments. \vspace{\vertSize} \\
		\lstinline!checkForComment(YYLTYPE location, char* construct)!  & \multirow{2}{\saxColSize}{endFile (also from \lstinline!globalHasComment!)} \\*
			 Check for comments before some construct. \vspace{\vertSize} \\
		\lstinline!switchHasDefault(YYLTYPE location, int progress)! & \multirow{2}{\saxColSize}{beginSwitch, registerDefault, endSwitch} \\*
		 Check that each \lstinline!switch! statement has a \lstinline!default! case. \vspace{\vertSize} \\
		\lstinline!switchCasesHaveBreaks(YYLTYPE location, int progress, int isCase)! & \multirow{2}{\saxColSize}{beginSwitch, registerDefault, registerCase, registerBreak, endSwitch} \\*
		 Check that each \lstinline!switch! case has a \lstinline!break! statement. \vspace{\vertSize} \\
		\lstinline!tooDeeplyNested(YYLTYPE location, int progress)! & \multirow{2}{\saxColSize}{beginCompoundStatement, endCompoundStatement} \\*
		 Check whether a region of code (i.e. a compound statement) nests too deeply. \vspace{\vertSize} \\
		\lstinline!useEnumNotDefine(YYLTYPE location, int progress)! & \multirow{2}{\saxColSize}{registerDefineIntegralType} \\*
			 Advises using \lstinline!enum! instead of \lstinline!#define! for declarations. \vspace{\vertSize} \\
		\lstinline!neverUseGotos(YYLTYPE location)! & \multirow{2}{\saxColSize}{registerGoto} \\*
			 Throw an error on any use of a \lstinline!GOTO! statement. \vspace{\vertSize} \\
		\lstinline!isVariableNameTooShort(YYLTYPE location, int progress, char* identifier)! & \multirow{2}{\saxColSize}{registerIdentifier, beginDeclaration, endDeclaration} \\*
		 Check if a variable's name exceeds a minimum length. \vspace{\vertSize} \\
		\lstinline!isMagicNumber(YYLTYPE location, int progress, char* constant)! & \multirow{2}{\saxColSize}{registerConstant, beginDeclaration, endDeclaration} \\*
			 Throw an error on encountering a magic number outside of a declaration. \vspace{\vertSize} \\
		\lstinline!globalHasComment(YYLTYPE location, int progress)! & \multirow{2}{\saxColSize}{beginFunctionDefinition, endFunctionDefinition, endDeclaration} \\*
			 Check if each global variable has a comment. \vspace{\vertSize} \\
		\lstinline!isLoopTooLong(YYLTYPE location)! & \multirow{2}{\saxColSize}{endWhile, endDoWhile, endFor} \\ *
			Check if the loop length exceeds a maximum length. \vspace{\vertSize} \\
		\lstinline!isCompoundStatementEmpty(YYLTYPE location, int progress)!  & \multirow{2}{\saxColSize}{beginCompoundStatement, endCompoundStatement} \\ *
			Check if the compound statement is empty. \vspace{\vertSize} \\
		\lstinline!tooManyFunctionsInFile(YYLTYPE location, int progress)! & \multirow{2}{\saxColSize}{endFile, beginFunctionDefinition} \\*
			 Check if there are too many functions in a file. \vspace{\vertSize} \\
		\lstinline!checkIfElsePlacement(YYLTYPE location, int progress)! & \multirow{2}{\saxColSize}{endIf, beginElse} \\ *
			Throw an error based on the placement of the else statement relative to the if statement.  \vspace{\vertSize} \\
		\lstinline!validateComment(YYLTYPE location, enum commandType command, char* text)! & \multirow{2}{\saxColSize}{beginFunctionDefinition, endFunctionDefinition, beginParameterList, endParameterList, registerIdentifier, beginCompoundStatement, registerReturnSomething} \\ *
			Check if function comments have the appropriate contents. Specifically check that the comment mentions each parameter (by name) and what the function returns. \vspace{\vertSize} \\ \\
		\lstinline!validatePointerParameters(YYLTYPE location, enum commandType command, char* identifier)! & \multirow{2}{\saxColSize}{beginFunctionDefinition, endFunctionDefinition, beginParameterList, registerParameter, endParameterList, registerIdentifier, registerPointer, endStatement} \\ *
			Check if each pointer type parameter into a function is mentioned within an \lstinline!assert()! before being used. \vspace{\vertSize} \\ \\ \\ \\
		\lstinline!void doFunctionsHaveCommonPrefix(YYLTYPE location, int progress, char* identifier)! & \multirow{2}{\saxColSize}{beginProgram, endProgram, endFile, beginFunctionDefinition, endFunctionDefinition, registerIdentifier} \\*
			Check that function names contain a common prefix.  \vspace{\vertSize} \\ \\ \\
		\lstinline!functionHasEnoughLocalComments(YYLTYPE location, int progress, int isComment)! & \multirow{2}{\saxColSize}{beginComment, beginFunctionDefinition, endFunctionDefinition, beginWhile, beginDoWhile, beginFor, beginIf, beginSwitch} \\*
			Check that there are enough local comments in the function relative to the number of control/selection statements.  \vspace{\vertSize} \\
		\lstinline!structFieldsHaveComments(YYLTYPE location, int progress)! & \multirow{2}{\saxColSize}{beginStructDefinition, registerStructField, endStructDefinition} \\*
			Check that all fields in a struct have a comment.  \\

\vspace{1mm}
\end{longtable}

\doublespacing
\chapter{Conventions and Necessities}
\label{conventions}

\section{General}

\begin{itemize}
\item Use the DynArray class to handle persistent arrays, stacks and queues. It is a dynamically growing array which holds void pointers. This is the base implementation of how comments are stored as well as the Hook module queues.
\item To change the tab size, edit the \lstinline{count} function inside c.l.
\end{itemize}

\section{Sax and Hooks Modules}

\begin{itemize}
\item When adding new calls, use the ``\lstinline{begin}'', ``\lstinline{register}'' and ``\lstinline{end}'' prefixes where \lstinline{begin} and \lstinline{end} are used with larger constructs and \lstinline{register} is used with constructs that are conceptually a single item (like a parameter).
\item Always make sure to add the \lstinline{lastCalled_set} function for any handlers that do not go through the Hooks module.
\item Be careful of doing memory management at a file level. Most of it is done at a program wide level because files are added onto a stack. This means that for three files, \programName sees three calls to \lstinline{beginFile} and before any of the \lstinline{endFile} calls. This makes it far easier to have allocation and releasing of memory at the single \lstinline{beginProgram} and \lstinline{endProgram} calls.
\item Keep all actual checks outside of the Sax handlers to improve code readability.
\item Prefix all calls that go through the Hooks module with ``\lstinline{h_}''.
\end{itemize}

\section{Checks Module}

\begin{itemize}
\item All error messages should be passed to their respective function without an ending newline; one 
will be added so that each error message appears on one line.
\item Use local static variables as opposed to global variables to determine context within checks.
\item Phrase check function names as questions or commands.
\item To compare entire locations use the methods in the Locations module. Comparing single elements can be done inline. 
\item Be careful not to free things which were either never allocated (e.g.\ the current location passed to the Sax\slash Hook handler), might be shared between objects (e.g.\ filename strings) or will be freed on its own later (e.g.\ comment texts and locations).
\item When adding a new check, add the function name and a significant (non-variable) part of the error message to the arrays in \lstinline{runOnTests.sh}. If changing the error message of an existing check, make sure to update the arrays.
\end{itemize}

\chapter{Progression of Development}

\programName's development has been reasonably linear and has consisted of slowly adding modules 
as situations arose. Getting the Bison and Flex to parse the sample C code took a significant portion of 
time at the beginning; especially the added elements such as tracking \lstinline{typedef}s and 
dynamically reading header files. Once the code could be read without issue, the next step was to start 
adding some minimal checks.

The first version of \programName consisted of the Main, Grammar and Lexer, and Checks modules 
(although they were not conceived as such at that point). At this stage, Checks contained four checks 
which were called directly from the actions in the grammar (\autoref{1.0grammar}). Comment tracking 
had been implemented inside Checks and was passed a different value for the beginning, middle and 
end of a comment. Context was determined by setting an enumerated value for the statement as a whole 
(underlined in \autoref{1.0grammar}). While this version was functional, it involved tedious manipulation 
of the grammar as well as very little ability to perform contextual processing.

\begin{figure}
\begin{lstlisting}[language=Caml, escapechar=\%]
selection_statement
	: IF '(' expression ')' statement {%\underline{\$\$ = IF\_SELECTION;}% ifHasBraces($5, @$);}
	| IF '(' expression ')' statement ELSE statement {%\underline{\$\$ = IF\_ELSE\_SELECTION;}% ifHasBraces($5, @$); ifHasBraces($7, @$);}
	| SWITCH '(' expression ')' statement
	;
\end{lstlisting}
\caption[Version 1.0 Grammar Excerpt]{Version 1.0 Grammar Excerpt where \lstinline{ifHasBraces} is a check that determines if an \lstinline{if} statement had braces.}
\label{1.0grammar}
\end{figure}

This dependency on the grammar file was the motivation to change the framework in version 2. The first 
step was to adopt the SAX style of processing. The alternative was to try to use an AST and Visitor 
Pattern (like PMD and Checkstyle) but this would have involved a lot of overhead to write the framework 
code. The SAX style is relatively lightweight and was the far easier (and simpler) alternative. The 
transition from version 1 to version 2 was fairly painless and immediately allowed for additional checks to 
be added. The comment tracking system was moved into its own module and all of the previous 
enumerated value contexts were removed. However, in adding more checks, I realized that some calls 
into the Sax module were simply not going to be in the right order. 

This problem prompted final version (3) which added the Hooks module. The inspiration behind the 
hooks module was the queue of function pointers. The insight of storing the pointers to the event 
handlers made this entire implementation (and version) possible. After adding the Hooks module, I was 
able to add even more checks and focus on cleaning up the code. In the process of adding more checks, 
I decided to store the last called event handler in order to minimize the number of handlers any given 
check needed to be called from. This eventually lead to the \lstinline{lastCalledFunction} methods.  At 
this point I moved all the code regarding \lstinline{YYLTYPE}s into the Locations module and added finer 
grain methods to find relevant comments by location. 

\singlespacing
\nocite{*}
\bibliographystyle{plain}
\clearpage
\phantomsection
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{Bibliography}


\cleardoublepage
\pagestyle{plain}
\begin{flushright}
\vspace*{1.5in}
This paper represents my own work in accordance with University regulations.\\
\vspace*{.75in}
Erin Rosenbaum\\
April 15, 2011

\end{flushright}

\end{document}  