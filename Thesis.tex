\documentclass[12pt]{report}
\usepackage{setspace}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

%todonotes
\usepackage{todonotes}
\newcommand{\todoin}{\todo[inline]}

%code listings%%%
\usepackage{listings}
%\lstset{language=C}
\lstset{
	basicstyle=\ttfamily,
	tabsize=2,
	frame=single,
	breaklines=true,
	breakatwhitespace=true,
	breakindent=25pt,
	defaultdialect=[ANSI]C,
	showstringspaces=false
 }
%\def\lstlistlistingname{Code Excerpts}
\def\lstlistingname{Figure}
\newcommand{\refCode}{\lstlistingname \hspace{1mm}}
\usepackage[scaled=.8]{luximono}
   \usepackage[T1]{fontenc}
   \usepackage{textcomp}
%%%

%project name
\usepackage{xspace}
\newcommand{\projectname}{Project Name\xspace} 
\newcommand{\programName}{CritTer\xspace}

\usepackage{booktabs} %pretty tables
\usepackage[pdfauthor={ErinRosenbaum},pagebackref=true,pdftex]{hyperref}
%pdftitle={\projectname}

\newcounter{checkCounter}
\usepackage{ifthen}
\newcommand\chk[2][default]{\noindent%
  \refstepcounter{checkCounter} \thecheckCounter \hspace{1mm}
  \ifthenelse{\equal{#1}{default}}{
    #2 \label{#2} }{
    #2 \label{#1}
  }
}
\newcommand\chkref[1]{\hspace{.1mm} \ref{#1} \hspace{2mm}#1}

\usepackage{color}

\usepackage{versions}
\includeversion{PRINT}
\excludeversion{COLOR}

\usepackage{caption, subcaption}
\ExecuteOptions{tight,TABTOPCAP}

%for title page
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

%\doublespacing			% Ask per individual, also remove extra space in section headings

\begin{document}
\input{titlePage}
\pagenumbering{roman}

\listoftodos

\begin{abstract}
\todoin{Add an abstract}
\end{abstract}

\tableofcontents
\listoftables
\listoffigures

\cleardoublepage
\pagenumbering{arabic}

\chapter{Problem Description}

\begin{table}%[h]
	\caption{Error Checking}
	\label{errorChecking}
	\begin{center}
	\begin{tabular}{ccc}
		\toprule
		Types of Errors & Tools for Literature & Tools for Code \\
		\midrule
		Syntactic & Spell Check & Compiler \\
		Semantic & Grammar Check & \\ 
		Substantive & Audience/Grader & User/Tests \\
		\bottomrule
	\end{tabular}
	\end{center}
\end{table}

When one writes, one encounters three different types of errors: syntactic, semantic and substantive.  
In the case of writing literature, these errors take the form of spelling, grammar and substantive
mistakes. When writing code, they form syntax errors, poorly written code and malfunctioning code. 
Both spelling mistakes and syntax errors represent text that contains something outside the language 
(be it English, C, etc.). A passage with bad grammar and poorly written code both denote text that is 
technically valid but hard to understand. Finally, illogical arguments and malfunctioning code both 
imply errors in the ideas behind the text. 
There are tools to help one find these errors in both literature and code (see Table \ref
{errorChecking}). Spelling and grammar check exist in nearly every word processor; the reader 
highlights substantive errors in literature. With code, the compiler shows semantic errors and the user/
testing reveal substantive errors. Yet semantic error checking for code has been addressed by 
relatively few tools.

From a different point of view, this problem can be formulated in terms of software quality. 
Namely, there are two perspectives on software quality: that of the user and that of the programmer. 
Users evaluate software on whether or not it behaves as it ought to. In contrast, programmers evaluate 
software on whether or not it is easily maintainable. Minimally, maintainability implies that 
code is easy to read and update. Evaluating the user's perspective of a program is common and most 
easily accomplished through automated testing. Though it is possible to evaluate the programmers' 
perspective, tools that do so only check for certain qualities. Unfortunately, code quality is 
subjective, any tool that only performs pre-defined inspections will never be satisfactory to every 
programmer.

The biggest reason to perform semantic error checking is to improve readability (the 
ease with which another programmer can understand a piece of code). In the same way that 
grammatical errors in a paper often confound its underlying arguments, poorly written code can easily 
obscure its underlying function. Furthermore, readable code is easy to revise and update later. 

In the academic world, professors and TA's often read students' code, especially in introductory level
courses. In these courses, much of the focus is often on enforcing ``good style'' (though the definition 
varies from professor to professor).  The successful implementation of automated semantic error 
checking can immediately save work for professors by replacing the process of writing the same set of 
stylistic comments to many students with a set of automated warnings. Students can also directly 
benefit by applying this tool to their code before submitting assignments --- giving them the chance to 
improve their grades as well as their coding habits.

In an industrial setting, where it is necessary to read or edit another's code, maintaining readability is 
essential. Projects are often handed over to new employees or teams who are then expected to be 
able to contribute immediately. Poorly organized or written code makes this daunting task 
onerous. Most successful software companies make use of a codified internal style but the 
enforcement of this policy falls to the employees. Many transgressions are simply due to inattention 
and could easily be solved by an automated reminder system. Such a tool would reduce the need to 
bother one's peers with another round of reviews, allowing the entire team to be more productive. 

\chapter{Related Products}

There are some tools that try to fill the semantic error checking gap. Each approaches the 
problem differently, but all succeed in finding some semantic errors. Three such tools are Splint\cite
{splint-manual} , PMD\cite{pmd}, and Checkstyle\cite{checkstyle}.

 \todoin{add explicit comparison between these tools and my tool}
\section{Splint}
Splint is a tool for ``statically checking C programs for security vulnerabilities and programming 
mistakes"\cite[p.\ 9]{splint-manual}. It works exactly as my program does from the students'
perspective, i.e.\ as a command-line program which prints warnings and errors to \lstinline{stdout}. 
Splint displays warnings about basic semantic errors like assignments with mismatched types and 
ignored return values. With more effort, programmers can add annotations (i.e.\ fancy comments) that 
give Splint a specification to check against. These annotations allow for stronger checks like memory 
management, null pointers and ``violations of information hiding''\cite[p. 9]{splint-manual}. An 
example of annotations in action are the following abstract type declarations (\refCode \ref{splint-annotations}).

\begin{figure}[h]
\caption{Splint Annotations} 
\label{splint-annotations}
\begin{lstlisting}[frame=single, language=C]
typedef /*@abstract@*/ /*@mutable@*/ char *mstring;
typedef /*@abstract@*/ /*@immutable@*/ int weekDay;
\end{lstlisting}
\small{These annotations define \lstinline{mstring} and \lstinline{weekDay} as abstract types and further specify that they are mutable/immutable respectively.}
\end{figure}

While these annotations provide an extensive feature set, they are a huge inconvenience. They 
require programmers to specifically write their code to meet the specification, not only of the client, but 
also of the tool. For new programmers (often the ones who need the most error checking), these 
annotations are almost impossible to implement on top of learning to program as suggested by  
David Evans (one of the authors) in a private email. He states:
\begin{quote} \singlespacing
One of the goals of the original design of 
Splint was for programmers who add no annotations to start getting some useful warnings right away, 
including warnings that encourage them to start adding annotations.  For some aspects, such as 
\lstinline{/*@null@*/} annotations I think this has worked okay, but for others like abstract types, 
memory management, etc. I don't think it has worked very well, and the warnings on these issues tend 
to either make developers want to stop using Splint, or at least just turn off all the warnings of that type, 
rather than start adding the annotations needed to enable better checking.\cite{evans-email} 
\end{quote}

\section{PMD and Checkstyle}
PMD is a tool for checking Java Code that is integrated into a dozen or so different popular IDEs.
PMD comes premade with over 250 checks broken up mostly by purpose such as Braces Rules, 
Basic Rules, Coupling Rules, etc. Some checks also deal explicitly with a certain 
library or platform like Android, Jakarta and JUnit. PMD functions by passing source code into a 
JavaCC-generated parser and receiving an Abstract Syntax Tree (a.k.a.\ AST, a tree-based model of 
the source code). PMD then traverses the AST and calls each rule in the RuleSet to check for any
violations. This pattern of examining a tree of nodes is called the Visitor Pattern\cite{design-patterns}. 
The RuleSet is an XML file that can be edited to augment the functionality of PMD with customized 
rules. Rules are written in their own classes and extend a base implementation. The rule itself can 
override three functions (start, visit and end) to perform various checks against the source code based 
on the nodes in the AST. Here is the ``dummy" example from the PMD website which counts how 
many expressions are in the source code (see \refCode \ref{pmd-rule}).
\todoin{why PMD doesn't work}

\begin{figure}
\caption[Example PMD Rule]{Example PMD Rule counting the number expressions}
\label{pmd-rule}
\begin{lstlisting}[language=Java]
package net.sourceforge.pmd.rules;

import java.util.concurrent.atomic.AtomicLong;
import net.sourceforge.pmd.AbstractJavaRule;
import net.sourceforge.pmd.RuleContext;
import net.sourceforge.pmd.ast.ASTExpression;

public class CountRule extends AbstractJavaRule {

	private static final String COUNT = "count";

	@Override
	public void start(RuleContext ctx) {
		ctx.setAttribute(COUNT, new AtomicLong());
		super.start(ctx);
	}

	@Override
	public Object visit(ASTExpression node, Object data) {
		// How many Expression nodes are there in all files parsed! 
		RuleContext ctx = (RuleContext)data;
		AtomicLong total = (AtomicLong)ctx.getAttribute(COUNT);
		total.incrementAndGet();
		return super.visit(node, data);
	}

	@Override
	public void end(RuleContext ctx) {
		AtomicLong total = (AtomicLong)ctx.getAttribute(COUNT);
		addViolation(ctx, null, new Object[] { total });
		ctx.removeAttribute(COUNT);
		super.start(ctx);
	}
}
\end{lstlisting}
\end{figure}

Checkstyle mimics PMD in function but provides different checks out of the box (namely those 
regarding duplicate code, class design, whitespace, etc). It also uses the Visitor Pattern and 
provides ways to examine the beginning and ends of the tree as well as each node. New rules are 
added through an XML file and similarly passed to Checkstyle at runtime. Here is example check 
which determines how many methods are in a class (see \refCode \ref{checkstyle-rule}).
\todoin{pad this out into its own}
\nocite{framaC}

\begin{figure}
\caption[Example Checkstyle Check]{Example Checkstyle Check counting the number of methods in 
a class}
\label{checkstyle-rule}
\begin{lstlisting}[language=Java]
package com.mycompany.checks;
import com.puppycrawl.tools.checkstyle.api.*;

public class MethodLimitCheck extends Check
{
    private static final int DEFAULT_MAX = 30;
    private int max = DEFAULT_MAX;

    @Override
    public int[] getDefaultTokens()
    {
        return new int[]{TokenTypes.CLASS_DEF, TokenTypes.INTERFACE_DEF};
    }

    @Override
    public void visitToken(DetailAST ast)
    {
        // find the OBJBLOCK node below the CLASS_DEF/INTERFACE_DEF
        DetailAST objBlock = ast.findFirstToken(TokenTypes.OBJBLOCK);
        
        // count the number of direct children of the OBJBLOCK that 
        // are METHOD_DEFS
        int methodDefs = objBlock.getChildCount(TokenTypes.METHOD_DEF);
        
        // report error if limit is reached
        if (methodDefs > this.max) {
            log(ast.getLineNo(),
                "too many methods, only " + this.max + " are allowed");
        }
   }
}
\end{lstlisting}
\end{figure}


\chapter{Version 1}

\begin{singlespace}
\textit{Note: the following chapters describe my progress in creating \projectname by looking at each 
successive version. If you would like to skip ahead please go to Chapter \ref{chap:FinalVersion} on 
page \pageref{chap:FinalVersion}.} \end{singlespace}
\vspace{3mm} 

This version represents the basic implementation of my goal: a customizable style checker for C code.
It is built off of Flex and Bison which create a lexical analyzer and a parser from a set of source 
files. These two elements combine into one larger program, \programName, which takes a .c file as 
input.  \programName parses the input file by recognizing each code construction as part of the valid 
C grammar (these possible constructions are known as a grammar rules). While parsing the code, 
\programName executes any function associated with the grammar rule (see \refCode \ref{grammar1.0}, 
where functions are underlined). These functions are the checks which are stored in a different file. 
Additionally, checks can be called from the beginning or end of each file or the entire program.
\todoin{mention begin/end of file/program calls}

\begin{figure} 
\caption{Excerpt of the Grammar File from v1.0}
\label{grammar1.0}
\begin{lstlisting}[language=Caml, escapechar=\%]
parameter_list
	: parameter_declaration
	| parameter_list `,' parameter_declaration %\underline{\{tooManyParameters(@1);\}}%
	;

parameter_declaration
	: declaration_specifiers declarator
	| declaration_specifiers abstract_declarator
	| declaration_specifiers
	;

selection_statement
	: IF `(' expression `)' statement 	%\underline{\{\$\$ = IF\_SELECTION; ifHasBraces(\$5, @\$);\}}%
	| IF `(' expression `)' statement ELSE statement %\underline{\{\$\$ = IF\_ELSE\_SELECTION, ifHasBraces(\$5, @\$); ifHasBraces(\$7, @\$);\}}%
	| SWITCH `(' expression `)' statement
	;

iteration_statement
	: WHILE `(' expression `)' statement
	| DO statement WHILE `(' expression `)' `;'
	| FOR `(' expression_statement expression_statement `)' statement
	| FOR `(' expression_statement expression_statement expression `)' statement
	;

function_definition
	: declaration_specifiers declarator declaration_list compound_statement %\underline{\{isFunctionTooLong(@\$);\}}%
	| declaration_specifiers declarator compound_statement %\underline{\{isFunctionTooLong(@\$);\}}%
	| declarator declaration_list compound_statement %\underline{\{isFunctionTooLong(@\$);\}}%
	| declarator compound_statement %\underline{\{isFunctionTooLong(@\$);\}}%
	;
\end{lstlisting}
\end{figure} 
\newpage

\section{Checks}

To check a stylistic issue, one must first figure out how the issue is represented in the grammar and 
then add a function call inside that grammar rule. Each check can not only take advantage of the type 
of construction being formed (like Function \ref{hasBraces} in Table \ref{implementedChecks1.0}), it 
can also look at the location of each construction. This allows checks to determine the length of a 
construction (like Function \ref{isFunctionTooLong}). It also allows checks to determine if they are still 
working with the same construction (like Function \ref{tooManyParameters}). Function \ref{CPlusPlusComments} 
is actually implemented through the lexer and is called on recognition of ``\lstinline{\\}''. \refCode \ref{checks.c1.0} 
shows examples of check functions.

\begin{table}
	\caption{Implemented Checks in v1.0}
	\label{implementedChecks1.0}
	\begin{center}
	\begin{tabular}{l p{10cm}}
		\toprule
		Function & Purpose \\
		\midrule
		\chk[hasBraces]{ifHasBraces} & Determines if the statement following an \lstinline!if! is surrounded by \{\} \\
		\chk{isFunctionTooLong} & Determines if a function's length exceeds the maximum number of lines\\
		\chk{tooManyParameters} & Determines if there a function exceeds the maximum number of input parameters \\
		\chk{CPlusPlusComments} & Throws an error on finding C++ style single-line comments \\
		\bottomrule
	\end{tabular}
	\end{center}
\end{table}

\begin{figure}
\caption{Excerpt of Checks.c from v1.0}
\label{checks.c1.0}
\begin{lstlisting}[language=C]
void ifHasBraces(enum tree_code statementValue, YYLTYPE location) {
	if (statementValue != COMPOUND_STATEMENT) {
		lyyerror(location, "Please use braces after all if statements");
	}
}

void isFunctionTooLong(YYLTYPE location) {
	int MAX_FUNCTION_LENGTH = 100; /* Arbitrary Maximum */
	
	if (location.last_line - location.first_line + 1 >= MAX_FUNCTION_LENGTH) {
		lyyerror(location, "Function is too lengthy");
	}
}

void tooManyParameters(YYLTYPE location) {
	int MAX_NUM_PARAMETERS = 7; /* Arbitrary Maximum */
	static int numParameters = -1;
	static YYLTYPE prevLoc;
	
	if (location.first_line != prevLoc.first_line || numParameters == -1) {
		if (numParameters != -1 && numParameters >= MAX_NUM_PARAMETERS) {
			char string[200];
			sprintf(string,
					"Please use less than %d function parameters, you used %d",
					MAX_NUM_PARAMETERS, numParameters);
			lyyerror(prevLoc, string);
		}
		numParameters = 1;
	}
	numParameters++;
	prevLoc = location;
}

void CPlusPlusComments(YYLTYPE location) {
	lyyerror(location, "Don't use C++ style comments");
}

\end{lstlisting}
\end{figure}


\section{Limitations}
There are two main limitations to this version:\ adding a check is a hassle and C preprocessor 
directives are not handled. As described above, adding a check is nontrivial because of the 
interaction with the grammar file. It requires users to be reasonably familiar with not only grammar files 
but the C grammar itself. The second limitation is that all macros except \lstinline{#include} are 
completely ignored. While unfortunate, this implementation is far easier than the alternative:\ 
effectively compiling and tracking all definitions, expressions and \lstinline{#ifndef}s. Includes are 
parsed only so far as to include any local file -- all standard files are ignored because they rely on 
types that were defined as macros. To make this system work for average student C files, the lexer has 
\todo{``average student C files'' -- reword?}
the \lstinline{size_t} type built in. A minor issue is \programName does not follow the paths of files -- 
meaning that it will not run on code residing in a subfolder of the working directory.

\section{Version 1.1}
This version simply adds more functionality (checks) to version 1.0 without changing the overall structure of \programName.

\subsection{Checks}
Version 1.1 changes Function \ref{hasBraces} from Version 1.0 as well as adds several new checks (see 
Table \ref{implementedChecks1.1}). This version also stores comment text and locations for the 
duration of the program. The appropriate comment is found by searching through the stored location-
comment pairs for locations within a certain range of a specified location. For example, in Function 
\ref{checkForComment}, each function definition results in a search for any comment within 5 lines of the 
declaration. Comments and their locations are stored in two dynamically sized global arrays.

\begin{table}
\caption{Additional Checks in 1.1}
\label{implementedChecks1.1}
	\begin{tabular}{l p{10cm}}
		\toprule
		Function & Purpose \\
		\midrule
		\chkref{hasBraces} & Determines if the statement following an \lstinline!if!, \lstinline$for$, or \lstinline$while$ is surrounded by \lstinline!{}! \\
		\chk{checkForComment} & Throws an error if a function does not have an associated comment \\
		\chk{switchHasDefault} & Throws an error if a switch statement does not include a \lstinline$default$ case \\
	\end{tabular}
\end{table}

\chapter{Version 2}
made sax style implementation of version 1.1

\section{Limitations}
because of the ambiguous nature of the grammar its impossible to get some of the begin calls at the 
actual beginning of the construct.

\section{Version 2.1}

\begin{table}[h]
\caption{Additional Checks in 2.1}
\label{implementedChecks2.1}
	\begin{tabular}{l p{10cm}}
		\toprule
		Function & Purpose \\
		\midrule
		\chk{switchCasesHaveBreaks} & Make sure all cases (including the \lstinline$default$) have a \lstinline$break$ statement \\
		\chk{tooDeeplyNested} & Throws error if a region is too deeply nested \\
		\chk{useEnumNotConstOrDefine} & Throws error for using \lstinline$const$ or \lstinline$#define$ to define integral constants \\
		\bottomrule
	\end{tabular}
\end{table}

\chapter{Final Product aka Version X}
\label{chap:FinalVersion}

\chapter{What \programName Does}

\programName reads in a set of C source code files and determines if they contain any of the 
specified semantic errors. It is run through the command line inside one's 
working directory. \programName is given a list of .c/h files to check and reads through each in the 
given order, stopping to read through any locally included header files. Upon encountering an error,
\programName prints out the full location of the error, a warning level and an error message to 
\lstinline{stderr} (an example is shown in \refCode \ref{errorExample}). 

\begin{figure}
\caption{Example Error and Corresponding Message}
\label{errorExample}
\begin{subfigure}[b]{.5\linewidth}
\caption{test.c}
\label{errorExampleCode}
\begin{lstlisting}[numbers=left, firstnumber=92,xleftmargin=1cm]
	for (int q = 0; q<5; q++) {
		printf("hi");
	}
\end{lstlisting}
\end{subfigure}
\begin{subfigure}[b]{.5\linewidth}
\caption{stderr}
\label{errorExampleStderr}
\begin{lstlisting}[xleftmargin=1cm]
test.c:92.22-92.23: big problem: Do not use magic numbers
\end{lstlisting}
\end{subfigure}
\small{Here, \programName is complaining that the for loop's exit condition contains a `magic number', in this case 5. The error message contains the location of the error, the warning level and then the error message.}
\end{figure}

The administrator is responsible for defining the set of checked semantic errors. \programName 
comes with a set of predefined checks that the administrator may use or discard at their discretion. 
Checks are event driven and are called when the appropriate element in the code is reached. For 
example, checking for a minimum length of each variable name happens when \programName 
recognizes a variable inside a declaration. The administrator can write their own checks as functions 
to be invoked at each of the relevant callback points.

The set of predefined checks are listed below in Table \ref{predefinedChecks}.

\begin{table}
\caption{Predefined Checks}
\label{predefinedChecks}
	\begin{center}
	\begin{tabular}{l p{10cm}}
		\toprule
		Check Name & Purpose \\
		\midrule
		isFileTooLong & Check if the file exceeds a maximum length. \\
		hasBraces & Check if there are braces surrounding an if statement. \\
		isFunctionTooLongByLines & Check if a function exceeds a maximum line count. \\
		isFunctionTooLongByStatements & Checks if a function exceeds a maximum statement count. \\
		tooManyParameters & Check if there are too many parameters in the function declaration. \\
		CPlusPlusComments & Throw an error on C++ style single line comments. \\
		checkForComment & Check for comments before some construct. \\
		switchHasDefault & Check that each \lstinline!switch! statement has a \lstinline!default! case. \\
		switchCasesHaveBreaks & Check that each \lstinline!switch! case has a \lstinline!break! statement. \\
		tooDeeplyNested & Check whether a region of code (i.e. a compound statement) nests too deeply. \\
		useEnumNotConstOrDefine & Advises using \lstinline!enum! instead of \lstinline!const! or \lstinline!#define! for declarations. \\
		neverUseGotos & Throw an error on any use of a \lstinline!GOTO! statement. \\
		isVariableNameTooShort & Check if a variable's name exceeds a minimum length. \\
		isMagicNumber & Throw an error on encountering a magic number outside of a declaration. \\
		globalHasComment & Check if each global variable has a comment. \\
		isLoopTooLong & Check if the loop length exceeds a maximum length. \\
		isCompoundStatementEmpty  & Check if the compound statement is empty. \\
		tooManyFunctionsInFile & Check if there are too many functions in a file. \\
		checkIfElsePlacement & Throw an error based on the placement of the else statement relative to the if statement.  \\
		validateComment & Check if function comments have the appropriate contents. Specifically check that the comment mentions each parameter (by name) and what the function returns. \\
		\bottomrule
	\end{tabular}
	\end{center}
\end{table}

\chapter{How \programName Works}

Figure \ref{moduleInteraction} shows how \programName is divided up into multiple semi-autonomous modules. Each of these has a unique function and is designed to keep the code as clean as possible. The ``Knowledge Barrier'' distinguishes the easily customizable and understandable modules from those which should not be modified without extreme caution. These modules in turn can be conceptually grouped into three categories: \hyperref[parsingTheCode]{Parsing the Code}, \hyperref[howChecksAreCalled]{How Checks are Called} and \hyperref[howChecksAreWritten]{How Checks are Written}.

\begin{figure}[h]
\caption{Module Interaction of \programName}
\label{moduleInteraction}
\begin{center}
\processifversion{PRINT}{\includegraphics[scale=0.6]{ClassInteractionPrint}}
\processifversion{COLOR}{\includegraphics[scale=0.6]{ClasInteractionColor}}
\end{center}
\end{figure}


\section{Parsing the Code}
\label{parsingTheCode}

\programName is built on top of Bison and Flex, a parser generator and a lexical analyzer 
respectively. These two programs each take in a specification file (which define a set of tokens and a 
corresponding context free grammar) and output a set of C files to programmatically parse code. 
Control goes back and forth between the lexical analyzer, which recognizes code as distinct elements, 
and the parser, which determines how the elements fit together. \programName's specification files 
describe valid ANSI C code but \programName does not compile or in anyway track the contents. This 
means, for example, that \programName sees any variable or function name as just as an 
\lstinline{IDENTIFIER} (any set of letters that does not already designate a variable type) without any 
context as to where it was defined or used before. Because \programName cannot evaluate code, it 
cannot follow preprocessor directives. \programName therefore reads all of the code in the file, even if 
it would not actually be included during compilation. In order to combat the issue of multiple inclusion 
of header files, \programName stores the name of each file it opens and does not open that file again, 
even if it is included from another file. Standard header files (such as \lstinline{stdlib.h} and 
\lstinline{strings.h}) are not included because they define types within preprocessor directives (which 
\programName cannot evaluate and therefore cannot recognize as a type). To adjust for this issue, the 
lexer instead contains a hack for determining if character strings in the code are \lstinline{IDENTIFIER}s 
or type names. Namely, the lexer does a string compare against common types defined in headers 
such as \lstinline{FILE}, \lstinline{pid_t}, etc. If any of these hardcoded checks pass, then the lexer tells 
the parser it has found a type name instead of an \lstinline{IDENTIFIER}.

Each grammar rule can contain multiple actions which consist of C code. These actions can 
also reference the location of the entire rule or any of single component of it through the prebuilt 
location mechanism. Bison and Flex track the location of any token or grammar construct. They store 
this information in a \lstinline{YYLTYPE} structure. (Normally a \lstinline{YYLTYPE} contains 4 fields, 
\lstinline{first_line}, \lstinline{first_column}, \lstinline{last_line} and \lstinline{last_column}; however, I 
have also added a \lstinline{filename} field in order to produce more accurate checks and error 
messages across a set of files.) \programName calls the event handlers from these actions, passing in 
the location of the relevant construction (see \refCode \ref{grammar}, where actions are underlined). 
Some actions are `hidden' in subroutines in order to avoid ambiguities within the grammar.

\begin{figure} 
\caption{Excerpt of the Grammar}
\label{grammar}
\begin{lstlisting}[language=Caml, escapechar=\%]
parameter_list
	: parameter_declaration											%\underline{\{h\_registerParameter(@\$);\}}%
	| parameter_list ',' parameter_declaration	%\underline{\{h\_registerParameter(@3);\}}%
	;

parameter_declaration
	: declaration_specifiers declarator
	| declaration_specifiers abstract_declarator
	| declaration_specifiers
	;

beginIF : /*empty*/ %\underline{\{beginIf(@\$);\}}%

selection_statement
	: IF beginIF '(' expression ')' statement %\underline{\{endIf(@\$);\}}%
	| IF beginIF '(' expression ')' statement ELSE %\underline{\{endIf(@6); beginElse(@7);\}}% statement	%\underline{\{endElse(@9);\}}%
	| SWITCH %\underline{\{beginSwitch(@1);\}}% '(' expression ')' statement %\underline{\{endSwitch(@\$);\}}%
	;

beginFOR : /*empty*/ %\underline{\{beginFor(@\$);\}}%

iteration_statement
	: WHILE %\underline{\{beginWhile(@1);\}}% '(' expression ')' statement %\underline{\{endWhile(@\$);\}}%
	| DO %\underline{\{beginDoWhile(@1);\}}% statement WHILE '(' expression ')' ';' %\underline{\{endDoWhile(@\$);\}}%
	| FOR beginFOR '(' expression_statement expression_statement ')' statement	%\underline{\{endFor(@\$);\}}%
	| FOR beginFOR '(' expression_statement expression_statement expression ')' statement %\underline{\{endFor(@\$);\}}%
	| FOR beginFOR '(' declaration expression_statement ')' statement %\underline{\{endFor(@\$);\}}%
	| FOR beginFOR '(' declaration expression_statement expression ')' statement	%\underline{\{endFor(@\$);\}}%

\end{lstlisting}
\end{figure} 

Instead of writing them from scratch, I found the Flex and Bison specification files 
online\cite{originalGrammar} and have modified them to add additional functionality. The only major 
modification of the actual grammar was to add the ability to recognize and dynamically add 
\lstinline{typdef} definitions as types. These type names are stored in an internal symbol table and the 
lexer checks to make sure that any potential \lstinline{IDENTIFIER}s are not already listed there. In 
order to accommodate the inclusion of header files, I had to expand the given lexer functionality to 
transfer control between files. The specific method of using a stack of buffers/files is heavily inspired 
from the examples in the O'Reily Flex \& Bison book\cite{flex-and-bison}. When transferring to a 
different file, the lexer adds the current file to a stack with its file pointer, internal state, and current line 
number. When it reaches the end of the file, the lexer pops the current file off the stack and goes back 
to its previous state. The end of program occurs when there are no more files on the 
stack.\footnote{\programName starts by adding all of the given files to the stack and dynamically adding 
additional header files. While this pre-loading is not strictly in concordance with the model of adding 
header files, it simplified the interface between the main module and the lexer/parser.} 
\todo{Add that I added a comment state?}


\section{How Checks are Called}
\label{howChecksAreCalled}

\programName is event based and is largely inspired by SAX\cite{saxHomepage}. SAX is a 
framework which allows programmers to use event handlers to parse XML files. SAX typically uses
event handlers for the beginning and end of each XML element as well as to capture the text in 
between. \programName calls event handlers at the beginning and end of constructs (functions, 
declarations, statements, parameter lists, etc) as well as when it finds singular elements (variable 
names, \lstinline{break} statements, parameters, etc). In the code, handlers are prefaced by the words 
\lstinline{begin}, \lstinline{end} and \lstinline{register} to signal at what point each is called (as shown 
in \refCode \ref{grammar}). Each handler is passed, at minimum, the location of the relevant code; 
however, \lstinline{begin} handlers only know the location of the beginning of the construct since the 
entire construct has not been read yet. Each of these event handlers exist in the file sax.c/h which in 
turn call the administrator defined checks. While these checks could be written into the event handlers 
themselves, it is conventional to separate them into their own functions (and files) in order to preserve 
the readability of the sax.c file and the code in general.

Unfortunately some handlers cannot actually be called at the time the construction is recognized. This 
is due to the fact that Bison executes actions as they are encountered inside each grammar rule. At the 
beginning of a rule, Bison would not know which rule it was actually matching when it needed to 
execute the action. In all the rules listed in \refCode \ref{grammar}, the action is preceded by some 
distinguishing token (like \lstinline{WHILE}) or by the entire rule. However \refCode \ref{hookGrammar} 
shows how some rules that both need actions at the beginning of the statement and lack distinguishing 
tokens. Specifically we would like to know when we start the beginning of a function definition but we 
cannot be sure that we are in a function definition until Bison finishes parsing the signature. To fix this 
issue I have added the hooks module. This module intercepts what would be normal calls within the 
SAX framework and then reorders them at the appropriate time. Each call into the module does one of 
two things: enqueues a SAX level function call and its location or dequeues any item after a specified 
location (\refCode \ref{hooksQueues}). With the beginning of a function, all the elements of the 
signature are placed on the queues and then dequeued when \lstinline{h_beginFunctionDefinition} is 
called. Another reason for the hooks module is to make the appropriate calls into the Sax layer 
regarding \lstinline{IDENTIFIER}s and numeric constants. Bison only deals with the tokens as opposed 
to their text whereas Flex deals with the actual text. The hooks module takes separate calls from both 
programs regarding the location and the actual text of \lstinline{IDENTIFIER}s and constants and routes 
them into a combined call in the SAX layer. This can best be seen in \refCode \ref{handlerTimeline}.

\begin{figure}
\caption{Additional Excerpt of the Grammar}
\label{hookGrammar}
\begin{lstlisting}[language=Caml, escapechar=\%]
declarator
	: pointer direct_declarator
	| direct_declarator
	;

direct_declarator
	: IDENTIFIER			 %\underline{\{h\_registerIdentifier(@\$);\}}%
	| '(' declarator ')'
	| direct_declarator '['  %\underline{\{h\_beginDirectDeclarator(@1);\}}% constant_expression ']'	 %\underline{\{h\_endDirectDeclarator(@\$);\}}%
	| direct_declarator '['  %\underline{\{h\_beginDirectDeclarator(@1);\}}% ']'						%\underline{\{h\_endDirectDeclarator(@\$);\}}%
	| direct_declarator '('  %\underline{\{h\_beginDirectDeclarator(@1);\}}% parameter_type_list ')'	%\underline{\{h\_endDirectDeclarator(@\$);\}}%
	| direct_declarator '('  %\underline{\{h\_beginDirectDeclarator(@1);\}}% identifier_list ')'		%\underline{\{h\_endDirectDeclarator(@\$);\}}%
	| direct_declarator '('  %\underline{\{h\_beginDirectDeclarator(@1);\}}% ')'						%\underline{\{h\_endDirectDeclarator(@\$);\}}%
	;


function_definition
	: declaration_specifiers declarator %\underline{\{h\_beginFunctionDefinition(@2);\}}% declaration_list compound_statement %\underline{\{endFunctionDefinition(@\$);\}}%
	| declaration_specifiers declarator %\underline{\{h\_beginFunctionDefinition(@2);\}}%} compound_statement %\underline{\{endFunctionDefinition(@\$);\}}%
	| declarator %\underline{\{h\_beginFunctionDefinition(@1);\}}% declaration_list compound_statement %\underline{\{endFunctionDefinition(@\$);\}}%
	| declarator %\underline{\{h\_beginFunctionDefinition(@1);\}}% compound_statement %\underline{\{endFunctionDefinition(@\$);\}}
	;
\end{lstlisting}
\end{figure}

\begin{figure}
\caption{Representation of the hooks module}
\label{hooksQueues}
\begin{center}
\begin{subfigure}[t]{.4\linewidth}
	\caption{}
	\label{hooksQueuesA}
	\includegraphics[scale=0.5]{hooksQueuesPartA.pdf}
\end{subfigure}
\begin{subfigure}[t]{.4\linewidth}
	\caption{}
	\label{hooksQueuesB}
	\includegraphics[scale=0.5]{hooksQueuesPartB.pdf}
\end{subfigure} \\
\vspace{4mm}
\begin{subfigure}[t]{.4\linewidth}
	\caption{}
	\label{hooksQueuesC}
	\includegraphics[scale=0.5]{hooksQueuesPartC.pdf}
\end{subfigure}
\begin{subfigure}[t]{.4\linewidth}
	\caption{}
	\label{hooksQueuesD}
	\includegraphics[scale=0.5]{hooksQueuesPartD.pdf}
\end{subfigure}
\end{center}
\small{(\subref{hooksQueuesA}) The initial queue with functions associated to locations 11, 12 and 13. \\(\subref{hooksQueuesB}) The queue after another function/location pair has been enqueued. \\ (\subref{hooksQueuesC}) The call at location 15 causes a call into the Sax layer followed by every stored call after the given location (12) in the queue. \\ (\subref{hooksQueuesD}) The resulting queue. }
\end{figure}

\begin{figure}
\caption{Timeline of event handler calls}
\label{handlerTimeline}
\begin{center}
\begin{tabular}{llc}
\toprule
Hooks & Sax  & Relevant Code\\
\midrule
h\_registerIdentifierText & & \lstinline!example! \\
h\_registerIdentifier & & \lstinline!example! \\
h\_beginParameterList & & \lstinline!(! \\
h\_registerIdentifierText & & \lstinline!a! \\
h\_registerIdentifier & & \lstinline!a! \\
h\_registerParameter & & \lstinline!int a! \\
h\_registerIdentifierText & & \lstinline!b! \\
h\_registerIdentifier & & \lstinline!b! \\
h\_registerParameter & & \lstinline!double b! \\
h\_endParameterList & & \lstinline!)! \\
h\_beginFunctionDefinition & beginFunctionDefinition & \\
 & registerIdentifier & \lstinline!example! \\
 & beginParameterList & \lstinline!(! \\
 & registerParameter & \lstinline!int a! \\
 & registerIdentifier & \lstinline!a! \\
 & registerParameter & \lstinline!double b!\\
 & registerIdentifier & \lstinline!b!\\
 & endParameterList & \lstinline!)!\\
N/A & beginCompoundStatement & \lstinline!{!\\
\ldots & \ldots & \lstinline!...! \\
N/A & endCompoundStatement & \lstinline!}!\\
N/A & endFunctionDefinition \\
 \bottomrule
\end{tabular}
\end{center}
\small{The timeline of calls into the hooks and sax module for:
 \lstinline!void example(int a, double b) {...}!
}
\end{figure}
\newpage

\section{How Checks Are Written}
\label{howChecksAreWritten}

Minimally, each check needs access to the location of the code construct in case an error needs to be 
produced. However, checks often need additional information regarding the surrounding context of 
the possible error. A simple example is the check against using magic numbers (\refCode 
\ref{checkWithContext}). Many programmers consider using numeric constants directly inside the code 
very poor style and recommend defining a variable to hold that value. \programName should therefore 
only throw an error when it finds an magic number inside a normal statement (as opposed to inside a 
declaration where it is necessarily defined). This check then needs to know every time a declaration 
begins and ends as well as each time a number is found. Alternatively, one can set global 
variables regarding the context and minimize the number of parameters to each check.

\newcommand{\yyerror}{\lstinline{yyerror}\xspace}
\newcommand{\lyyerror}{\lstinline{lyyerror}\xspace}
\newcommand{\lyyerrorf}{\lstinline{lyyerrorf}\xspace}

In order to throw an error, the administrator can use one of three error functions: \yyerror, \lyyerror, and 
\lyyerrorf. Each of these functions outputs an error message to \lstinline{stderr} preceded by the error's 
location in the code and a warning level (as seen in \refCode \ref{errorExample}). \yyerror and \lyyerrorf 
are each wrappers to \lyyerror, which takes in an error level (\lstinline{enum errorLevel}), a location 
(\lstinline{YYLTYPE}) and an error message (\lstinline{char *}). In essence, \lyyerror is really a wrapper 
to \lstinline{fprintf} and defines the formatting of all the error messages/locations. It is also the location 
to change the string value of the different error levels (currently, \lstinline{ERROR_HIGH}=``big 
problem'', \lstinline{ERROR_NORMAL}=``error'', and \lstinline{ERROR_LOW}=``low priority'').  
\lyyerrorf, instead of taking in an error message, takes a format string and a variable argument list 
which, through \lstinline{vsprintf} it uses to create an error message. It then passes the newly created 
message to \lyyerror with the rest of its arguments. \yyerror only takes an error message and calls 
\lyyerror with Bison's internal location in the code and a default high error level. This is because 
\yyerror is called internally through Bison to represent syntax errors. \yyerror is the only predefined 
error reporting function; \lyyerror is an extension suggested by O'Reily\cite{bison-and-flex} when using 
location tracking with Bison/Flex (the `l' represents the variable location). \lyyerrorf was created in the 
likes of \lstinline{printf} to deal with formatted error messages in one consolidated location.

\begin{figure}
\caption{Check with additional context}
\label{checkWithContext}
\begin{lstlisting}[language=C]
void isMagicNumber(YYLTYPE location, int progress, char* constant) {
	int acceptableNumbers[3] = {0, 1, 2};
	int numAcceptable = sizeof(acceptableNumbers)/sizeof(int);

	static int inDeclaration = 0;
	
	switch (progress) {
		case BEGINNING:
			inDeclaration++;
			break;
		case MIDDLE:
			if (inDeclaration == 0) {
				int number = (int)strtol(constant, (char**)NULL, 0);
				int i;

				/* see if number is within the acceptableNumbers array */
				for (i = 0; i < numAcceptable; i++) {
					if (number == acceptableNumbers[i]) {
						return;
					}
				}
				lyyerror(ERROR_HIGH, location, "Do not use magic numbers");
			}
			break;
		case END:
			inDeclaration--;
			break;
		default:
			break;
	}
}
\end{lstlisting}
\small{Throw an error on encountering a magic number outside of a declaration.}
\end{figure}

Additionally, there are two helper modules designed to facilitate writing checks: Locations and 
Comments. The Locations module contains a several functions to manipulate \lstinline{YYLTYPE}s.  
Specifically it contains methods to compare locations in various directions/distances as well as 
allocate, copy and free \lstinline{YYLTYPE}s. The Comments module tracks all the comments found 
while running \programName. Comment contents and locations are registered through calls from the 
Sax layer and are stored in a dynamic array. Additionally the module provides the ability to search 
through this array to find comments in or near a certain location (using the methods from Locations). 
Finally Comments provides a couple of useful functions when analyzing the comment itself: 
determining if a comment has words (as opposed to a deliminating comment in the form of 
\lstinline{/*----*/} etc.) and if a comment contains a word (with or without case sensitivity).

\chapter{Conventions}

\section{Sax}

\section{Hooks}

\section{Checks}

\begin{itemize}
\item All error messages should be passed to their respective function without an ending newline; one 
will be added so that each error message appears on one line.

\end{itemize}

\nocite{*}
\bibliographystyle{plain}
\clearpage
\phantomsection
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{Bibliography}

\end{document}  