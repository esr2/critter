\documentclass[12pt]{report}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

%todonotes
\usepackage{todonotes}
\newcommand{\todoin}{\todo[inline]}

%code listings%%%
\usepackage{listings}
%\lstset{language=C}
\lstset{
	basicstyle=\ttfamily,
	tabsize=2,
	frame=single,
	breaklines=true,
	breakatwhitespace=true,
	breakindent=25pt,
	defaultdialect=[ANSI]C,
	showstringspaces=false
 }
%\def\lstlistlistingname{Code Excerpts}
\def\lstlistingname{Figure}
\newcommand{\refCode}{\lstlistingname \hspace{1mm}}
\usepackage[scaled]{luximono}
   \usepackage[T1]{fontenc}
   \usepackage{textcomp}
%%%

%project name
\usepackage{xspace}
\newcommand{\projectname}{Project Name\xspace}
\newcommand{\programName}{PROGRAM\_NAME\xspace}

\usepackage{booktabs} %pretty tables
\usepackage[pdfauthor={ErinRosenbaum},pagebackref=true,pdftex]{hyperref}
%pdftitle={\projectname}

\newcommand{\tablerow}[1]{#1}

\usepackage{color}

%for title page
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\title{Customizable Style Checking for C Programs}
\author{Erin Rosenbaum}
%\date{}                                           % Activate to display a given date or no date

\begin{document}
%\maketitle
\input{titlePage}

\listoftodos

\begin{abstract}
\todoin{Add an abstract}
\end{abstract}

\tableofcontents

\listoftables
\listoffigures

\chapter{Problem Description}

\begin{table}%[h]
	\caption{Error Checking}
	\label{errorChecking}
	\begin{center}
	\begin{tabular}{ccc}
		\toprule
		Types of Errors & Tools for Literature & Tools for Code \\
		\midrule
		Syntactic & Spell Check & Compiler \\
		Semantic & Grammar Check & \\ 
		Substantive & Audience/Grader & User/Tests \\
		\bottomrule
	\end{tabular}
	\end{center}
\end{table}

When one writes, one encounters three different types of errors: syntactic, semantic and substantive.  
In the case of writing literature, these errors take the form of spelling, grammar and substantive
mistakes. When writing code, they form syntax errors, poorly written code and malfunctioning code. 
Both spelling mistakes and syntax errors represent text that contains something outside the language 
(be it English, C, etc.). A passage with bad grammar and poorly written code both denote text that is 
technically valid but hard to understand. Finally, illogical arguments and malfunctioning code both 
imply errors in the ideas behind the text. 
There are tools to help one find these errors in both literature and code (see Table \ref
{errorChecking}). Spelling and grammar check exist in nearly every word processor; the reader 
highlights substantive errors in literature. With code, the compiler shows semantic errors and the user/
testing reveal substantive errors. Yet semantic error checking for code has been addressed by 
relatively few tools.

From a different point of view, this problem can be formulated in terms of software quality. 
Namely, there are two perspectives on software quality: that of the user and that of the programmer. 
Users evaluate software on whether or not it behaves as it ought to. In contrast, programmers evaluate 
software on whether or not it is easily maintainable. Minimally, maintainability implies that 
code is easy to read and update. Evaluating the user’s perspective of a program is possible and most 
easily accomplished through automated testing. Though it is possible to evaluate the programmers' 
perspective, tools that do so only check for certain qualities. Unfortunately, code quality is 
subjective, any tool that only performs pre-defined inspections will never be satisfactory to every 
programmer.

The biggest reason to perform semantic error checking is to improve readability (the 
ease with which another programmer can understand a piece of code). In the same way that 
grammatical errors in a paper often confound its underlying arguments, poorly written code can easily 
obscure its underlying function. Furthermore, readable code is easy to revise and update later.  In an 
industrial or academic setting, where it is necessary to read or edit another's code, maintaining 
readability is essential. The successful implementation of automated semantic error checking 
can immediately save work for professors by replacing the process of writing the same set of stylistic 
comments to many students with a set of automated warnings.
Students can also directly benefit by applying this tool to their code before submitting assignments --- 
giving them the chance to improve their grades as well as their coding habits.
\todoin{separate academia and industry and play up both}

\chapter{Related Products}

There are some tools that try to fill the semantic error checking gap. Each approaches the 
problem differently, but all succeed in finding some semantic errors. Three such tools are Splint \cite
{splint-manual} , PMD \cite{pmd}, and Checkstyle \cite{checkstyle}.

 \todoin{add explicit comparison between these tools and my tool}
\section{Splint}
Splint is a tool for ``statically checking C programs for security vulnerabilities and programming 
mistakes" \cite[p.\ 9]{splint-manual}. It works exactly as my program does from the students'
perspective, i.e.\ as a command-line program which prints warnings and errors to \lstinline{stdout}. 
Splint displays warnings about basic semantic errors like assignments with mismatched types and 
ignored return values. With more effort, programmers can add annotations (i.e.\ fancy comments) that 
give Splint a specification to check against. These annotations allow for stronger checks like memory 
management, null pointers and ``violations of information hiding" \cite[p. 9]{splint-manual}. An 
example of annotations in action are the following abstract type declarations (\refCode \ref{splint-annotations}).

\begin{figure}[h]
\caption{Splint Annotations} 
\label{splint-annotations}
\begin{lstlisting}[frame=single, language=C]
typedef /*@abstract@*/ /*@mutable@*/ char *mstring;
typedef /*@abstract@*/ /*@immutable@*/ int weekDay;
\end{lstlisting}
\small{These annotations define \lstinline{mstring} and \lstinline{weekDay} as abstract types and further specify that they are mutable/immutable respectively.}
\end{figure}

While these annotations provide an extensive feature set, they are a huge inconvenience. They 
require programmers to specifically write their code to meet the specification, not only of the client, but 
also of the tool. For new programmers (often the ones who need the most error checking), these 
annotations are almost impossible to implement on top of learning to program as suggested by  
David Evans (one of the authors) in a private email. He states:
\begin{quote}
One of the goals of the original design of 
Splint was for programmers who add no annotations to start getting some useful warnings right away, 
including warnings that encourage them to start adding annotations.  For some aspects, such as 
\lstinline{/*@null@*/} annotations I think this has worked okay, but for others like abstract types, 
memory management, etc. I don't think it has worked very well, and the warnings on these issues tend 
to either make developers want to stop using Splint, or at least just turn off all the warnings of that type, 
rather than start adding the annotations needed to enable better checking." \cite{evans-email} 
\end{quote}

\section{PMD and Checkstyle}
PMD is a tool for checking Java Code that is integrated into a dozen or so different popular IDEs.
PMD comes premade with over 250 checks broken up mostly by purpose such as Braces Rules, 
Basic Rules, Coupling Rules, etc. Some checks also deal explicitly with a certain 
library or platform like Android, Jakarta and JUnit. PMD functions by passing source code into a 
JavaCC-generated parser and receiving an Abstract Syntax Tree (a.k.a.\ AST, a tree-based model of 
the source code). PMD then traverses the AST and calls each rule in the RuleSet to check for any
violations. This pattern of examining a tree of nodes is called the Visitor Pattern \cite{design-patterns}. 
The RuleSet is an XML file that can be edited to augment the functionality of PMD with customized 
rules. Rules are written in their own classes and extend a base implementation. The rule itself can 
override three functions (start, visit and end) to perform various checks against the source code based 
on the nodes in the AST. Here is the ``dummy" example from the PMD website which counts how 
many expressions are in the source code (see \refCode \ref{pmd-rule}).
\todoin{why PMD doesn't work}

\begin{figure}
\caption[Example PMD Rule]{Example PMD Rule counting the number expressions}
\label{pmd-rule}
\begin{lstlisting}[language=Java]
package net.sourceforge.pmd.rules;

import java.util.concurrent.atomic.AtomicLong;
import net.sourceforge.pmd.AbstractJavaRule;
import net.sourceforge.pmd.RuleContext;
import net.sourceforge.pmd.ast.ASTExpression;

public class CountRule extends AbstractJavaRule {

	private static final String COUNT = ``count";

	@Override
	public void start(RuleContext ctx) {
		ctx.setAttribute(COUNT, new AtomicLong());
		super.start(ctx);
	}

	@Override
	public Object visit(ASTExpression node, Object data) {
		// How many Expression nodes are there in all files parsed! 
		RuleContext ctx = (RuleContext)data;
		AtomicLong total = (AtomicLong)ctx.getAttribute(COUNT);
		total.incrementAndGet();
		return super.visit(node, data);
	}

	@Override
	public void end(RuleContext ctx) {
		AtomicLong total = (AtomicLong)ctx.getAttribute(COUNT);
		addViolation(ctx, null, new Object[] { total });
		ctx.removeAttribute(COUNT);
		super.start(ctx);
	}
}
\end{lstlisting}
\end{figure}

Checkstyle mimics PMD in function but provides different checks out of the box (namely those 
regarding duplicate code, class design, whitespace, etc). It also uses the Visitor Pattern and 
provides ways to examine the beginning and ends of the tree as well as each node. New rules are 
added through an XML file and similarly passed to Checkstyle at runtime. Here is example check 
which determines how many methods are in a class (see \refCode \ref{checkstyle-rule}).
\todoin{pad this out into its own}
\nocite{framaC}

\begin{figure}
\label{checkstyle-rule}
\caption[Example Checkstyle Check]{Example Checkstyle Check counting the number of methods in 
a class}
\begin{lstlisting}[language=Java]
package com.mycompany.checks;
import com.puppycrawl.tools.checkstyle.api.*;

public class MethodLimitCheck extends Check
{
    private static final int DEFAULT_MAX = 30;
    private int max = DEFAULT_MAX;

    @Override
    public int[] getDefaultTokens()
    {
        return new int[]{TokenTypes.CLASS_DEF, TokenTypes.INTERFACE_DEF};
    }

    @Override
    public void visitToken(DetailAST ast)
    {
        // find the OBJBLOCK node below the 
        // CLASS_DEF/INTERFACE_DEF
        DetailAST objBlock = ast.findFirstToken(TokenTypes.OBJBLOCK);
        // count the number of direct children of the
        // OBJBLOCK that are METHOD_DEFS
        int methodDefs = objBlock.getChildCount(TokenTypes.METHOD_DEF);
        // report error if limit is reached
        if (methodDefs > this.max) {
            log(ast.getLineNo(),
                "too many methods, only " + this.max + " are allowed");
        }
   }
}
\end{lstlisting}
\end{figure}


\chapter{Version 1}

\textit{Note: the following chapters describe my progress in creating \projectname by looking at each 
successive version. If you would like to skip ahead please go to Chapter \ref{chap:FinalVersion} on 
page \pageref{chap:FinalVersion}.}
\vspace{3mm} 

This version represents the basic implementation of my goal: a customizable style checker for C code.
It is built off of Flex and Bison which create a lexical analyzer and a parser from a set of source 
files. These two elements combine into one larger program, \programName, which takes a .c file as 
input.  \programName parses the input file by recognizing each code construction as part of the valid 
C grammar (these possible constructions are known as a grammar rules). While parsing the code, 
\programName executes any function associated with the grammar rule (see \refCode \ref{grammar1.0}, 
where functions are underlined). These functions are the checks which are stored in a different file. 
Additionally, checks can be called from the beginning or end of each file or the entire program.
\todoin{assume readers know about context free grammars -- explicitly use that term and add a footnote to explain it}
\todoin{explain locations somewhere (maybe final version?)}

\todo{try to show grammar excerpts with each check}
\begin{figure} 
\caption{Excerpt of the Grammar File from v1.0}
\label{grammar1.0}
\begin{lstlisting}[language=Caml, escapechar=\%]
selection_statement
	: IF `(' expression `)' statement 	%\underline{\{\$\$ = IF\_SELECTION; ifHasBraces(\$5, @\$);\}}%
	| IF `(' expression `)' statement ELSE statement %\underline{\{\$\$ = IF\_ELSE\_SELECTION, ifHasBraces(\$5, @\$); }%
			%\underline{ ifHasBraces(\$7, @\$);\}}%
	| SWITCH `(' expression `)' statement
	;

iteration_statement
	: WHILE `(' expression `)' statement
	| DO statement WHILE `(' expression `)' `;'
	| FOR `(' expression_statement expression_statement `)' statement
	| FOR `(' expression_statement expression_statement expression `)' statement
	;

function_definition
	: declaration_specifiers declarator declaration_list compound_statement %\underline{\{isFunctionTooLong(@\$);\}}%
	| declaration_specifiers declarator compound_statement %\underline{\{isFunctionTooLong(@\$);\}}%
	| declarator declaration_list compound_statement %\underline{\{isFunctionTooLong(@\$);\}}%
	| declarator compound_statement %\underline{\{isFunctionTooLong(@\$);\}}%
	;
\end{lstlisting}
\end{figure} 
\newpage

\section{Checks}

To check a stylistic issue, one must first figure out how the issue is represented in the grammar and 
then add a function call inside that grammar rule. Each check can not only take advantage of the type 
of construction being formed (like Function \tablerow{1} in Table \ref{implementedChecks1.0}), it can 
also look at the location of each construction. This allows checks to determine the length of a 
construction (like Function \tablerow{2} in Table \ref{implementedChecks1.0}). It also allows checks to 
determine if they are still working with the same construction (like Function \tablerow{3} in Table 
\ref{implementedChecks1.0}). \refCode \ref{checks.c1.0} shows examples of a check function.

\begin{table}
	\caption{Implemented Checks in v1.0}
	\label{implementedChecks1.0}
	\begin{center}
	\begin{tabular}{l l p{10cm}}
		\toprule
		& Function & Purpose \\
		\midrule
		1 & ifHasBraces & Determines if the statement following an \lstinline!if! is surrounded by \{\} \\
		2 & isFunctionTooLong & Determines if a function's length exceeds the maximum number of lines\\
		3 & tooManyParameters & Determines if there a function exceeds the maximum number of input parameters \\
		4 & CPlusPlusComments & Throws an error on finding C++ style single-line comments \\
		\bottomrule
	\end{tabular}
	\end{center}
\end{table}

\todo{add all the check code}
\begin{figure}
\caption{Excerpt of Checks.c from v1.0}
\label{checks.c1.0}
\begin{lstlisting}[language=C]
void isFunctionTooLong(YYLTYPE location) {
	int MAX_FUNCTION_LENGTH = 100; /*Arbitrary maximum */
	
	if (location.last_line - location.first_line + 1 >= MAX_FUNCTION_LENGTH) {
		lyyerror(location, ``Function is too lengthy'');
	}
}

void tooManyParameters(YYLTYPE location) {
	int MAX_NUM_PARAMETERS = 7; /*Arbitrary maximum */
	
	static int numParameters = -1;
	static YYLTYPE prevLoc;
	
	if (location.first_line != prevLoc.first_line ||
	    numParameters == -1) {
		if (numParameters != -1 && numParameters >= 
		    MAX_NUM_PARAMETERS) {
			char string[200];
			sprintf(string, ``Please use less than %d function parameters, you used %d'', MAX_NUM_PARAMETERS, numParameters);
			lyyerror(prevLoc, string);
		}
		
		numParameters = 1;
	}
	
	numParameters++;
	prevLoc = location;
}

\end{lstlisting}
\end{figure}


\section{Limitations}
There are two main limitations to this version:\ adding a check is a hassle and C preprocessor 
directives are not handled. As described above, adding a check is nontrivial because of the 
interaction with the grammar file. It requires users to be reasonably familiar with not only grammar files 
but the C grammar itself. The second limitation is that all macros except \lstinline{#include} are 
completely ignored. While unfortunate, this implementation is far easier than the alternative:\ 
effectively compiling and tracking all definitions, expressions and \lstinline{#ifndef}s. Includes are 
parsed only so far as to include any local file -- all standard files are ignored because they rely on 
types that were defined as macros. To make this system work for average student C files, the lexer has 
\todo{``average student C files'' -- reword?}
the \lstinline{size_t} type built in. A minor issue is \programName does not follow the paths of files -- 
meaning that it will not run on code residing in a subfolder of the working directory.

\section{Version 1.1}
This version simply adds more functionality (checks) to version 1.0 without changing the overall structure of \programName.

\subsection{Checks}
Version 1.1 changes Function \tablerow{1} from Version 1.0 as well as adds several new checks (see 
Table \ref{implementedChecks1.1}). This version also stores comment text and locations for the 
duration of the program. The appropriate comment is found by searching through the stored location-
comment pairs for locations within a certain range of a specified location. For example, in Function 
\tablerow{5}, each function definition results in a search for any comment within 5 lines of the 
declaration. Comments and their locations are stored in two dynamically sized global arrays.

\begin{table}
\caption{Additional Checks in 1.1}
\label{implementedChecks1.1}
	\begin{tabular}{l l p{10cm}}
		\toprule
		& Function & Purpose \\
		\midrule
		1 & hasBraces & Determines if the statement following an \lstinline!if!, \lstinline$for$, or \lstinline$while$ is surrounded by \{\} \\
		5 & checkForComment & Throws an error if a function does not have an associated comment \\
		6 & switchHasDefault & Throws an error if a switch statement does not include a \lstinline$default$ case \\
	\end{tabular}
\end{table}

\chapter{Version 2}
made sax style implementation of version 1.1

\section{Limitations}
because of the ambiguous nature of the grammar its impossible to get some of the begin calls at the 
actual beginning of the construct.

\section{Version 2.1}
made additions to 2.0 with 3?

\chapter{Final Product aka Version X}
\label{chap:FinalVersion}

\nocite{*}
\bibliographystyle{plain}
\bibliography{Bibliography}

\end{document}  